Cluster ID,Size,Template
1,740,2015-10-17 <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: <*> <*> <*> <*> <*>
2,232,2015-10-17 <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: <*> <*> <*>
3,360,"<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>"
4,3198,<*> <*> INFO [main] org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class <*> for class <*>
5,3695,2015-10-17 <*> INFO [main] <*> <*> <*> system <*>
6,355,<*> <*> INFO [main] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled
7,4900,<*> <*> INFO [main] org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
8,4900,<*> <*> INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
9,355,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for <*> to jobTokenSecretManager
10,355,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing <*> because: not enabled; too many maps; too much input;
11,355,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job <*> = <*> Number of splits = <*>
12,355,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job <*> = 1
13,355,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: <*> Transitioned from NEW to INITED
14,355,"<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job <*>"
15,710,<*> <*> INFO [main] org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
16,710,<*> <*> INFO [Socket Reader #1 for port <*> org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port <*>
17,355,<*> <*> INFO [main] org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server
18,960,<*> <*> INFO [IPC Server Responder] org.apache.hadoop.ipc.Server: <*> <*> <*> <*>
19,960,<*> <*> INFO [IPC Server listener on <*> org.apache.hadoop.ipc.Server: <*> <*> <*> <*> <*> <*>
20,355,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at <*>
21,400,2015-10-17 <*> INFO [main] <*> <*> to <*> <*> <*>
22,355,<*> <*> INFO [main] org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined
23,400,2015-10-17 <*> INFO [main] org.apache.hadoop.http.HttpServer2: <*> <*> <*> <*> <*>
24,710,<*> <*> INFO [main] org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context <*>
25,710,<*> <*> INFO [main] org.apache.hadoop.http.HttpServer2: adding path spec: <*>
26,400,2015-10-17 <*> INFO [main] <*> <*>
27,355,<*> <*> INFO [main] org.mortbay.log: Extract jar:file:/D:/hadoop-2.6.0-localbox/share/hadoop/yarn/hadoop-yarn-common-2.6.0-SNAPSHOT.jar!/webapps/mapreduce to <*>
28,2770,2015-10-17 <*> INFO [main] <*> <*> <*>
29,355,<*> <*> INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Web app /mapreduce started at <*>
30,355,<*> <*> INFO [main] org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
31,5010,<*> <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: <*> <*>
32,710,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: <*> is <*>
33,355,"<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: maxContainerCapability: <memory:8192, vCores:32>"
34,355,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500
35,355,<*> <*> INFO [main] org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
36,1225,<*> <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: <*> Transitioned from <*> to <*>
37,1700,<*> <*> INFO [CommitterEvent Processor <*> org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: <*>
38,11505,2015-10-17 <*> INFO [AsyncDispatcher event handler] <*> <*> <*> <*> <*>
39,35595,<*> <*> INFO [AsyncDispatcher event handler] <*> <*> <*> Transitioned from <*> to <*>
40,690,<*> <*> INFO <*> org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> vCores:1>
41,355,<*> <*> INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: <*> File: <*>
42,1600,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: <*> <*> <*> <*> <*> <*> CompletedReds:0 <*> ContRel:0 <*> RackLocal:0
43,4575,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for <*> <*> release= <*> <*> <*> <*> <*> <*>
44,29549,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
45,19345,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 1
46,4660,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container <*> to <*>
47,710,<*> <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The <*> file on the remote FS is <*>
48,355,<*> <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Adding #0 tokens and #1 secret keys for NM use for launching container
49,2550,2015-10-17 <*> INFO [AsyncDispatcher event handler] <*> <*> <*> <*> <*> <*>
50,8980,<*> <*> INFO [ContainerLauncher <*> org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: <*> for container <*> taskAttempt <*>
51,5315,2015-10-17 <*> INFO [ContainerLauncher <*> org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: <*> <*>
52,8980,<*> <*> INFO [ContainerLauncher <*> org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : <*>
53,4660,<*> <*> INFO [ContainerLauncher <*> org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for <*> : 13562
54,5295,<*> <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: <*> using containerId: <*> on NM: <*>
55,4940,<*> <*> INFO [Socket Reader #1 for port <*> SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for <*> (auth:SIMPLE)
56,4640,<*> <*> INFO [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : <*> asked for a task
57,146175,2015-10-17 <*> INFO [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
58,3135,<*> <*> INFO [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from <*>
59,1295,<*> <*> INFO [DefaultSpeculator background processing] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: DefaultSpeculator.addSpeculativeAttempt -- we are speculating <*>
60,1295,<*> <*> INFO [DefaultSpeculator background processing] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: We launched 1 speculations. Sleeping 15000 milliseconds.
61,990,<*> <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Scheduling a redundant attempt for task <*>
62,335,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold reached. Scheduling reduces.
63,1055,"<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent 0.1 <*> <*> <*> <*> <*> <*> <*> <*> netScheduledReduceResource:<memory:0, vCores:0>"
64,580,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*>
65,3785,<*> <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from <*> Container killed by the ApplicationMaster.
66,4416,Container killed on request. Exit code is 137
67,4416,Container exited with a non-zero exit code 137
68,5382,
69,91250,<*> <*> INFO [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: MapCompletionEvents request from <*> startIndex <*> maxEvents 10000
70,80,<*> <*> WARN [ResponseProcessor for block <*> org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception for block <*>
71,80,java.io.IOException: Bad response ERROR for block <*> from datanode <*>
72,974868,at <*>
73,80,<*> <*> WARN [DataStreamer for file <*> block <*> org.apache.hadoop.hdfs.DFSClient: Error Recovery for block <*> in pipeline <*> <*> bad datanode <*>
74,930,<*> <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Issuing kill to other attempt <*>
75,1080,<*> <*> WARN [CommitterEvent Processor <*> org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete <*>
76,1105,<*> <*> INFO [Socket Reader #1 for port <*> org.apache.hadoop.ipc.Server: Socket Reader #1 for port <*> readAndProcess from client <*> threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]
77,1328,java.io.IOException: An existing connection was forcibly closed by the remote host
78,35486,at <*> Method)
79,390,2015-10-17 <*> INFO [IPC Server handler <*> on <*> <*> <*> <*> <*> <*> <*>
80,245,<*> <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: <*> given a go for committing the task output.
81,260,<*> <*> INFO <*> org.apache.hadoop.mapreduce.v2.app.MRAppMaster: We are finishing cleanly so this is the last retry
82,540,<*> <*> INFO <*> org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify <*> isAMLastRetry: <*>
83,260,2015-10-17 <*> INFO <*> <*> <*> notified that <*> <*> true
84,270,<*> <*> INFO <*> org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
85,270,<*> <*> INFO <*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>
86,490,<*> <*> INFO <*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying <*> to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging
87,32,/history/done_intermediate/msrabi/job_1445062781478_0011-1445067474313-msrabi-pagerank-1445067766465-10-1-SUCCEEDED-default-1445067479468.jhist_tmp
88,1150,<*> <*> INFO [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: <*> <*> <*> <*> hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging
89,32,/history/done_intermediate/msrabi/job_1445062781478_0011_conf.xml_tmp
90,876,<*> to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging
91,16,/history/done_intermediate/msrabi/job_1445062781478_0011.summary
92,16,/history/done_intermediate/msrabi/job_1445062781478_0011_conf.xml
93,16,/history/done_intermediate/msrabi/job_1445062781478_0011-1445067474313-msrabi-pagerank-1445067766465-10-1-SUCCEEDED-default-1445067479468.jhist
94,250,<*> <*> INFO <*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()
95,30,2015-10-17 <*> INFO [Thread-101] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
96,235,<*> <*> INFO <*> org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Waiting for application to be successfully unregistered.
97,236,<*> <*> INFO <*> org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 <*> <*> <*> <*> <*> <*> <*>
98,235,<*> <*> INFO <*> org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://msra-sa-41:9000 <*>
99,250,<*> <*> INFO <*> org.apache.hadoop.ipc.Server: Stopping server on <*>
100,250,<*> <*> INFO [TaskHeartbeatHandler PingChecker] org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted
101,1696,2015-10-19 <*> INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: <*> <*> <*> <*>
102,4890,<*> <*> INFO [main] <*> Executing with tokens:
103,4545,"<*> <*> INFO [main] org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: <*> Ident: <*>"
104,4545,<*> <*> INFO [main] org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
105,4535,<*> <*> INFO [main] org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: <*>
106,4815,"<*> <*> INFO [main] org.apache.hadoop.conf.Configuration.deprecation: <*> is deprecated. Instead, use <*>"
107,4525,<*> <*> INFO [main] org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
108,4525,<*> <*> INFO [main] org.apache.hadoop.mapred.Task: Using ResourceCalculatorProcessTree : <*>
109,96,2015-10-19 <*> INFO [main] <*> Using <*> <*>
110,355,"<*> <*> INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: <*> <*> <*> ioSortFactor=10, memToMemMergeOutputsThreshold=10"
111,355,<*> <*> INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: <*> Thread started: EventFetcher for fetching Map Completion Events
112,2360,<*> <*> INFO <*> org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning <*> with <*> to <*>
113,2360,<*> <*> INFO <*> org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned <*> of <*> to <*> to <*>
114,2070,<*> <*> INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: <*> Got <*> new map-outputs
115,2345,<*> <*> INFO <*> org.apache.hadoop.mapreduce.task.reduce.Fetcher: for <*> sent hash and received reply
116,3335,<*> <*> INFO <*> org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: <*> Shuffling to disk since <*> is greater than maxSingleShuffleLimit <*>
117,3320,<*> <*> INFO <*> org.apache.hadoop.mapreduce.task.reduce.Fetcher: <*> about to shuffle output of map <*> decomp: <*> len: <*> to DISK
118,3245,<*> <*> INFO <*> org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput: Read <*> bytes from map-output for <*>
119,2275,<*> <*> INFO <*> org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: <*> freed by <*> in <*>
120,285,<*> <*> INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: <*> <*> <*> <*>
121,280,<*> <*> INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 0 in-memory map-outputs and <*> on-disk map-outputs
122,280,"<*> <*> INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging <*> files, <*> bytes from disk"
123,280,"<*> <*> INFO [main] org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce"
124,3390,<*> <*> INFO [main] org.apache.hadoop.mapred.Merger: Merging <*> sorted segments
125,3390,"<*> <*> INFO [main] org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with <*> segments left of total size: <*> bytes"
126,3125,<*> <*> INFO [main] org.apache.hadoop.mapred.Task: <*> is done. And is in the process of committing
127,240,<*> <*> INFO [main] org.apache.hadoop.mapred.Task: Task <*> is allowed to commit now
128,240,<*> <*> INFO [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task <*> to <*>
129,3080,<*> <*> INFO [main] org.apache.hadoop.mapred.Task: Task <*> done.
130,1585,<*> <*> INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: <*> metrics system shutdown complete.
131,8725,2015-10-19 <*> INFO [main] org.apache.hadoop.mapred.MapTask: <*> <*> <*>
132,8125,2015-10-19 <*> INFO [main] org.apache.hadoop.mapred.MapTask: <*> <*> <*> <*>
133,1230,2015-10-19 <*> INFO [main] <*> <*> <*>
134,3120,2015-10-19 <*> INFO [main] org.apache.hadoop.mapred.MapTask: <*> <*> <*> <*> = <*>
135,53390,<*> <*> INFO [main] org.apache.hadoop.mapred.MapTask: <*> = <*> <*> = <*> <*> = <*>
136,25210,<*> <*> INFO <*> org.apache.hadoop.mapred.MapTask: Finished spill <*>
137,22895,<*> <*> INFO [main] org.apache.hadoop.mapred.MapTask: (RESET) equator <*> kv <*> kvi <*>
138,3220,<*> <*> INFO [main] org.apache.hadoop.mapred.MapTask: Starting flush of map output
139,285,2015-10-19 <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: <*> <*> <*> <*> <*>
140,345,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
141,1130,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://msra-sa-41:9000]
142,190,2015-10-19 <*> INFO [main] <*> <*> to <*> <*> <*>
143,190,2015-10-19 <*> INFO [main] org.apache.hadoop.http.HttpServer2: <*> <*> <*> <*> <*>
144,190,2015-10-19 <*> INFO [main] <*> <*>
145,4835,2015-10-19 <*> INFO [AsyncDispatcher event handler] <*> <*> <*> <*> <*>
146,1100,2015-10-19 <*> INFO [AsyncDispatcher event handler] <*> <*> <*> <*> <*> <*>
147,2235,2015-10-19 <*> INFO [ContainerLauncher <*> org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: <*> <*>
148,61010,2015-10-19 <*> INFO [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
149,215,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: All maps assigned. Ramping up all remaining reduces:1
150,210,2015-10-19 <*> INFO [IPC Server handler <*> on <*> <*> <*> <*> <*> <*> <*>
151,422,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: <*> <*> ScheduledReds:0 AssignedMaps:0 <*> <*> <*> <*> ContRel:0 <*> <*>
152,140,2015-10-19 <*> INFO <*> <*> <*> notified that <*> <*> true
153,12,/history/done_intermediate/msrabi/job_1445182159119_0001-1445235687678-msrabi-word+count-1445236299685-10-1-SUCCEEDED-default-1445235697856.jhist_tmp
154,12,/history/done_intermediate/msrabi/job_1445182159119_0001_conf.xml_tmp
155,6,/history/done_intermediate/msrabi/job_1445182159119_0001.summary
156,6,/history/done_intermediate/msrabi/job_1445182159119_0001_conf.xml
157,6,/history/done_intermediate/msrabi/job_1445182159119_0001-1445235687678-msrabi-word+count-1445236299685-10-1-SUCCEEDED-default-1445235697856.jhist
158,10,"2015-10-19 14:31:55,905 INFO [Thread-105] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
159,1139,2015-10-18 <*> INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: <*> <*> <*> <*>
160,5670,2015-10-18 <*> INFO [main] org.apache.hadoop.mapred.MapTask: <*> <*> <*>
161,5855,2015-10-18 <*> INFO [main] org.apache.hadoop.mapred.MapTask: <*> <*> <*> <*>
162,880,2015-10-18 <*> INFO [main] <*> <*> <*>
163,2280,2015-10-18 <*> INFO [main] org.apache.hadoop.mapred.MapTask: <*> <*> <*> <*> = <*>
164,20,<*> <*> WARN [main] org.apache.hadoop.mapred.Task: Failure sending status update: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: <*> destination host is: <*>
165,136122,at <*> Source)
166,330,Caused by: java.io.IOException: An existing connection was forcibly closed by the remote host
167,220,<*> <*> INFO [communication thread] org.apache.hadoop.mapred.Task: Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: <*> destination host is: <*>
168,935,<*> <*> INFO <*> org.apache.hadoop.ipc.Client: Retrying connect to server: <*> Already tried <*> time(s); maxRetries=45
169,11650,<*> <*> INFO <*> <*> org.apache.hadoop.ipc.Client: Retrying connect to server: <*> Already tried <*> time(s); maxRetries=45
170,80,<*> <*> WARN [main] org.apache.hadoop.hdfs.BlockReaderFactory: I/O error constructing remote block reader.
171,120,java.net.NoRouteToHostException: No route to host: no further information
172,50,"2015-10-18 <*> WARN [main] org.apache.hadoop.hdfs.DFSClient: Failed to connect to <*> for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information"
173,25,"2015-10-18 <*> INFO [main] org.apache.hadoop.hdfs.DFSClient: Could not obtain <*> from any node: java.io.IOException: No live nodes contain block <*> after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry..."
174,30,"2015-10-18 <*> WARN [main] org.apache.hadoop.hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for <*> msec."
175,26560,<*> <*> WARN <*> org.apache.hadoop.ipc.Client: Address change detected. Old: <*> New: <*>
176,20,2015-10-18 <*> WARN <*> org.apache.hadoop.hdfs.DFSClient: <*> <*>
177,31818,java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
178,31980,Caused by: java.net.NoRouteToHostException: No route to host: no further information
179,38094,... <*> more
180,13,<*> <*> <*> <*> <*> <*> <*> <*> <*> java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
181,62,2015-10-18 <*> INFO [main] <*> <*> <*> for <*> <*>
182,60,2015-10-18 <*> INFO <*> <*> <*> <*> <*> java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
183,61,2015-10-18 <*> INFO [main] <*> Using <*> <*>
184,115,2015-10-18 <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: <*> <*> <*> <*> <*>
185,120,2015-10-18 <*> INFO [main] <*> <*> to <*> <*> <*>
186,120,2015-10-18 <*> INFO [main] org.apache.hadoop.http.HttpServer2: <*> <*> <*> <*> <*>
187,120,2015-10-18 <*> INFO [main] <*> <*>
188,3155,2015-10-18 <*> INFO [AsyncDispatcher event handler] <*> <*> <*> <*> <*>
189,12,2015-10-18 <*> INFO [RMCommunicator Allocator] <*> <*> <*> <*> <*>
190,222,2015-10-18 <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: <*> <*> <*> <*> AssignedReds:0 <*> CompletedReds:0 <*> <*> <*> <*>
191,675,2015-10-18 <*> INFO [AsyncDispatcher event handler] <*> <*> <*> <*> <*> <*>
192,1430,2015-10-18 <*> INFO [ContainerLauncher <*> org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: <*> <*>
193,32925,2015-10-18 <*> INFO [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
194,60,"<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Cannot assign container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:1024, vCores:1>, Priority: <*> Token: Token { kind: ContainerToken, service: <*> }, ] for a map as either container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true"
195,95,<*> <*> ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Container complete event for unknown container id <*>
196,26500,<*> <*> WARN [LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for <*> for <*> seconds. Will retry shortly ...
197,45,"<*> <*> WARN [ResponseProcessor for block <*> org.apache.hadoop.hdfs.DFSClient: Slow ReadProcessor read fields took <*> (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: ERROR downstreamAckTimeNanos: 0, targets: <*> <*>"
198,10,2015-10-18 <*> WARN [DataStreamer for file <*> block <*> org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
199,10,2015-10-18 <*> WARN [DataStreamer for file <*> block <*> org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception
200,2400,<*> <*> ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: ERROR IN CONTACTING RM.
201,42,java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: <*> destination host is: <*>
202,2395,<*> <*> WARN [RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030
203,5195,"<*> <*> INFO <*> <*> org.apache.hadoop.ipc.Client: Retrying connect to server: <*> Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
204,2922,java.io.IOException: Failed on local exception: <*> <*> <*> <*> <*> <*> Host Details : local host is: <*> destination host is: <*>
205,2874,Caused by: java.io.IOException: Couldn't set up IO streams
206,2898,Caused by: <*>
207,20,2015-10-18 <*> <*> [IPC Server handler <*> on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
208,17,<*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
209,12,<*> <*> <*> <*> <*> <*> org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
210,10,2015-10-18 <*> WARN [CommitterEvent Processor <*> org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Task cleanup failed for attempt <*>
211,2,"2015-10-18 18:06:26,139 ERROR [eventHandlingThread] <*> <*> <*> <*> <*> <*>"
212,42,org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
213,42,Caused by: java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
214,50,<*> <*> INFO [Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: <*> failures on node <*>
215,50,<*> <*> INFO [Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added <*> to list of failed maps
216,15,2015-10-18 <*> ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Could not contact RM after 360000 milliseconds.
217,15,2015-10-18 <*> ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Error communicating with RM: Could not contact RM after 360000 milliseconds.
218,18,org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Could not contact RM after 360000 milliseconds.
219,120,2015-10-18 <*> INFO <*> <*> <*> notified that <*> <*> true
220,30,"<*> <*> INFO <*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event <*>"
221,10,2015-10-18 <*> INFO [Thread-560] org.apache.hadoop.service.AbstractService: Service <*> failed in state STOPPED; cause: org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected.
222,24,org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected.
223,5,"2015-10-18 18:10:58,562 WARN [Thread-560] org.apache.hadoop.service.CompositeService: When stopping the service JobHistoryEventHandler : org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected."
224,65,<*> <*> INFO <*> org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING <*>
225,65,<*> <*> INFO <*> org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : <*>
226,60,2015-10-18 <*> WARN <*> org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>
227,144,Caused by: java.net.UnknownHostException: <*>
228,60,2015-10-18 <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from <*> cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>
229,10,"2015-10-18 18:10:58,593 INFO [Thread-560] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
230,45,"<*> <*> INFO <*> org.apache.hadoop.ipc.Client: Retrying connect to server: <*> Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
231,15,2015-10-18 <*> ERROR <*> org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Exception while unregistering
232,5,"2015-10-18 18:10:59,593 INFO [Thread-560] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:3 ScheduledReds:1 AssignedMaps:9 AssignedReds:0 CompletedMaps:1 CompletedReds:0 ContAlloc:11 ContRel:1 HostLocal:7 RackLocal:3"
233,15,2015-10-18 <*> INFO <*> org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Skipping cleaning up the staging dir. assuming AM will be retried.
234,15,2015-10-18 <*> WARN <*> org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Graceful stop failed
235,48,Caused by: java.net.SocketException: Permission denied: no further information
236,75,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Recovery is enabled. Will try to recover from previous life on best effort basis.
237,95,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Previous history file is at <*>
238,55,<*> <*> INFO [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Read completed tasks from history <*>
239,480,"<*> <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Recovering task <*> from prior app attempt, status was SUCCEEDED"
240,3999,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: <*> <*> ScheduledReds:0 <*> <*> <*> CompletedReds:0 <*> ContRel:0 <*> <*>
241,135,2015-10-18 <*> INFO [IPC Server handler <*> on <*> <*> <*> <*> <*> <*> <*>
242,12,/history/done_intermediate/msrabi/job_1445144423722_0020-1445162504986-msrabi-pagerank-1445164035248-10-1-SUCCEEDED-default-1445162513713.jhist_tmp
243,12,/history/done_intermediate/msrabi/job_1445144423722_0020_conf.xml_tmp
244,6,/history/done_intermediate/msrabi/job_1445144423722_0020.summary
245,6,/history/done_intermediate/msrabi/job_1445144423722_0020_conf.xml
246,6,/history/done_intermediate/msrabi/job_1445144423722_0020-1445162504986-msrabi-pagerank-1445164035248-10-1-SUCCEEDED-default-1445162513713.jhist
247,10,2015-10-18 <*> INFO [Thread-116] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
248,17280,2015-10-17 <*> INFO [main] org.apache.hadoop.mapred.MapTask: <*> <*> <*>
249,17900,2015-10-17 <*> INFO [main] org.apache.hadoop.mapred.MapTask: <*> <*> <*> <*>
250,7110,2015-10-17 <*> INFO [main] org.apache.hadoop.mapred.MapTask: <*> <*> <*> <*> = <*>
251,353,<*> <*> INFO [main] org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: <*>
252,1570,<*> <*> INFO [main] org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping <*> metrics system...
253,1304,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved <*> to /default-rack
254,413,2015-10-17 <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: PendingReds:0 <*> <*> <*> <*> <*> <*> <*> ContRel:0 <*> <*>
255,12,/history/done_intermediate/msrabi/job_1445094324383_0001-1445094472971-msrabi-word+count-1445095231162-10-1-SUCCEEDED-default-1445094488479.jhist_tmp
256,12,/history/done_intermediate/msrabi/job_1445094324383_0001_conf.xml_tmp
257,6,/history/done_intermediate/msrabi/job_1445094324383_0001.summary
258,6,/history/done_intermediate/msrabi/job_1445094324383_0001_conf.xml
259,6,/history/done_intermediate/msrabi/job_1445094324383_0001-1445094472971-msrabi-word+count-1445095231162-10-1-SUCCEEDED-default-1445094488479.jhist
260,10,2015-10-17 <*> INFO [Thread-112] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
261,500,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping down all scheduled reduces:0
262,500,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Going to preempt 1 due to lack of space for maps
263,615,"2015-10-18 <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent 0.2 <*> <*> <*> <*> <*> <*> <*> <*> netScheduledReduceResource:<memory:0, vCores:0>"
264,12,/history/done_intermediate/msrabi/job_1445144423722_0024-1445162508959-msrabi-pagerank-1445163619058-10-1-SUCCEEDED-default-1445162981270.jhist_tmp
265,12,/history/done_intermediate/msrabi/job_1445144423722_0024_conf.xml_tmp
266,6,/history/done_intermediate/msrabi/job_1445144423722_0024.summary
267,6,/history/done_intermediate/msrabi/job_1445144423722_0024_conf.xml
268,6,/history/done_intermediate/msrabi/job_1445144423722_0024-1445162508959-msrabi-pagerank-1445163619058-10-1-SUCCEEDED-default-1445162981270.jhist
269,10,"2015-10-18 18:20:22,979 INFO [Thread-111] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
270,10,2015-10-17 <*> INFO [Thread-71] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
271,180,java.io.IOException: Bad connect ack with firstBadLink as <*>
272,100,<*> <*> INFO <*> org.apache.hadoop.hdfs.DFSClient: Abandoning <*>
273,60,java.net.ConnectException: Connection timed out: no further information
274,25,"<*> <*> WARN [main] org.apache.hadoop.hdfs.DFSClient: Failed to connect to <*> for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information"
275,30,<*> <*> INFO [main] org.apache.hadoop.hdfs.DFSClient: Successfully connected to <*> for <*>
276,35,"<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Releasing unassigned and invalid container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: <*> }, ]. RM may have assignment issues"
277,752,2015-10-17 <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: <*> <*> <*> <*> <*> <*> CompletedReds:0 <*> ContRel:1 <*> <*>
278,12,/history/done_intermediate/msrabi/job_1445076437777_0005-1445076558325-msrabi-pagerank-1445077274793-10-1-SUCCEEDED-default-1445076957160.jhist_tmp
279,12,/history/done_intermediate/msrabi/job_1445076437777_0005_conf.xml_tmp
280,6,/history/done_intermediate/msrabi/job_1445076437777_0005.summary
281,6,/history/done_intermediate/msrabi/job_1445076437777_0005_conf.xml
282,6,/history/done_intermediate/msrabi/job_1445076437777_0005-1445076558325-msrabi-pagerank-1445077274793-10-1-SUCCEEDED-default-1445076957160.jhist
283,10,"2015-10-17 18:21:15,387 INFO [Thread-106] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
284,125,<*> <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: TaskAttempt killed because it ran on unusable node <*> <*>
285,12,/history/done_intermediate/msrabi/job_1445087491445_0002-1445088243318-msrabi-word+count-1445091063334-13-1-SUCCEEDED-default-1445088256684.jhist_tmp
286,12,/history/done_intermediate/msrabi/job_1445087491445_0002_conf.xml_tmp
287,6,/history/done_intermediate/msrabi/job_1445087491445_0002.summary
288,6,/history/done_intermediate/msrabi/job_1445087491445_0002_conf.xml
289,6,/history/done_intermediate/msrabi/job_1445087491445_0002-1445088243318-msrabi-word+count-1445091063334-13-1-SUCCEEDED-default-1445088256684.jhist
290,10,2015-10-17 <*> INFO [Thread-91] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
291,420,<*> <*> INFO [EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Ignoring obsolete output of <*> map-task: <*>
292,35,2015-10-17 <*> INFO [main] org.apache.hadoop.mapred.Merger: Merging 4 intermediate segments out of a total of 13
293,100,<*> <*> INFO [DataStreamer for file <*> org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
294,50,<*> <*> INFO [DataStreamer for file <*> org.apache.hadoop.hdfs.DFSClient: Abandoning <*>
295,5,"2015-10-17 21:49:33,809 INFO [communication thread] org.apache.hadoop.mapred.Task: Communication exception: java.net.ConnectException: Call From MSRA-SA-39/172.22.149.145 to minint-fnanli5.fareast.corp.microsoft.com:49594 failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused"
296,6,Caused by: java.net.ConnectException: Connection timed out: no further information
297,975,"2015-10-17 <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent <*> <*> <*> <*> <*> <*> <*> <*> <*> netScheduledReduceResource:<memory:0, vCores:0>"
298,275,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Killing <*> because it is running on unusable <*>
299,310,<*> <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from <*> <*> <*> <*> <*> <*> <*>
300,152,2015-10-19 <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: PendingReds:0 <*> <*> <*> <*> <*> <*> <*> ContRel:0 <*> <*>
301,12,/history/done_intermediate/msrabi/job_1445182159119_0011-1445240987301-msrabi-pagerank-1445241443017-10-1-SUCCEEDED-default-1445240997344.jhist_tmp
302,12,/history/done_intermediate/msrabi/job_1445182159119_0011_conf.xml_tmp
303,6,/history/done_intermediate/msrabi/job_1445182159119_0011.summary
304,6,/history/done_intermediate/msrabi/job_1445182159119_0011_conf.xml
305,6,/history/done_intermediate/msrabi/job_1445182159119_0011-1445240987301-msrabi-pagerank-1445241443017-10-1-SUCCEEDED-default-1445240997344.jhist
306,10,"2015-10-19 15:57:27,736 INFO [Thread-112] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
307,12,/history/done_intermediate/msrabi/job_1445076437777_0002-1445076557428-msrabi-pagerank-1445076863096-10-1-SUCCEEDED-default-1445076564680.jhist_tmp
308,12,/history/done_intermediate/msrabi/job_1445076437777_0002_conf.xml_tmp
309,6,/history/done_intermediate/msrabi/job_1445076437777_0002.summary
310,6,/history/done_intermediate/msrabi/job_1445076437777_0002_conf.xml
311,6,/history/done_intermediate/msrabi/job_1445076437777_0002-1445076557428-msrabi-pagerank-1445076863096-10-1-SUCCEEDED-default-1445076564680.jhist
312,10,"2015-10-17 18:14:34,299 INFO [Thread-98] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
313,12,/history/done_intermediate/msrabi/job_1445062781478_0020-1445073079681-msrabi-pagerank-1445073609167-10-1-SUCCEEDED-default-1445073321328.jhist_tmp
314,12,/history/done_intermediate/msrabi/job_1445062781478_0020_conf.xml_tmp
315,6,/history/done_intermediate/msrabi/job_1445062781478_0020.summary
316,6,/history/done_intermediate/msrabi/job_1445062781478_0020_conf.xml
317,6,/history/done_intermediate/msrabi/job_1445062781478_0020-1445073079681-msrabi-pagerank-1445073609167-10-1-SUCCEEDED-default-1445073321328.jhist
318,30,2015-10-17 <*> INFO [Thread-104] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
319,10,"2015-10-19 <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent <*> <*> vCores:-8> <*> <*> <*> <*> <*> <*> netScheduledReduceResource:<memory:0, vCores:0>"
320,12,/history/done_intermediate/msrabi/job_1445182159119_0014-1445240989463-msrabi-pagerank-1445241794508-10-1-SUCCEEDED-default-1445240998871.jhist_tmp
321,12,/history/done_intermediate/msrabi/job_1445182159119_0014_conf.xml_tmp
322,6,/history/done_intermediate/msrabi/job_1445182159119_0014.summary
323,6,/history/done_intermediate/msrabi/job_1445182159119_0014_conf.xml
324,6,/history/done_intermediate/msrabi/job_1445182159119_0014-1445240989463-msrabi-pagerank-1445241794508-10-1-SUCCEEDED-default-1445240998871.jhist
325,10,"2015-10-19 16:03:14,992 INFO [Thread-79] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
326,10,2015-10-19 <*> WARN [main] org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in <*>
327,102,Caused by: org.apache.hadoop.fs.FSError: java.io.IOException: There is not enough space on the disk
328,108,Caused by: java.io.IOException: There is not enough space on the disk
329,28,<*> <*> INFO [main] org.apache.hadoop.mapred.Task: Runnning cleanup for the task
330,10,2015-10-19 <*> ERROR <*> org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Shuffle failed : local error on this node: 04DN8IQ/10.86.164.138
331,20,2015-10-19 <*> WARN [main] org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete <*>
332,20,2015-10-19 <*> <*> [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in <*>
333,12,<*> <*> <*> <*> <*> <*> <*> Diagnostics report from <*> Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in <*>
334,12,/history/done_intermediate/msrabi/job_1445094324383_0004-1445094473098-msrabi-word+count-1445096128795-10-1-SUCCEEDED-default-1445094484150.jhist_tmp
335,12,/history/done_intermediate/msrabi/job_1445094324383_0004_conf.xml_tmp
336,6,/history/done_intermediate/msrabi/job_1445094324383_0004.summary
337,6,/history/done_intermediate/msrabi/job_1445094324383_0004_conf.xml
338,6,/history/done_intermediate/msrabi/job_1445094324383_0004-1445094473098-msrabi-word+count-1445096128795-10-1-SUCCEEDED-default-1445094484150.jhist
339,10,"2015-10-17 23:35:33,576 INFO [Thread-155] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
340,10,"2015-10-19 14:26:28,977 <*> [IPC Server handler 10 on 49792] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_1445182159119_0002_m_000007_0/file.out"
341,6,<*> <*> <*> <*> <*> <*> <*> Diagnostics report from attempt_1445182159119_0002_m_000007_0: Error: org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_1445182159119_0002_m_000007_0/file.out
342,12,/history/done_intermediate/msrabi/job_1445182159119_0002-1445235687677-msrabi-word+count-1445236914959-10-1-SUCCEEDED-default-1445235697502.jhist_tmp
343,12,/history/done_intermediate/msrabi/job_1445182159119_0002_conf.xml_tmp
344,6,/history/done_intermediate/msrabi/job_1445182159119_0002.summary
345,6,/history/done_intermediate/msrabi/job_1445182159119_0002_conf.xml
346,6,/history/done_intermediate/msrabi/job_1445182159119_0002-1445235687677-msrabi-word+count-1445236914959-10-1-SUCCEEDED-default-1445235697502.jhist
347,10,2015-10-19 <*> INFO [Thread-86] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
348,5,"2015-10-19 14:26:28,852 INFO [main] org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@6a6585ee"
349,6,java.lang.NullPointerException
350,6,<*> <*> <*> <*> <*> <*> <*> <*> <*> org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_1445182159119_0002_m_000007_0/file.out
351,20,2015-10-17 <*> INFO [Thread-56] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
352,506,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 <*> <*> <*> <*> <*> <*> <*> <*>
353,12,/history/done_intermediate/msrabi/job_1445062781478_0015-1445067477119-msrabi-pagerank-1445068216511-10-1-SUCCEEDED-default-1445067831801.jhist_tmp
354,10,2015-10-17 <*> INFO [Thread-107] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
355,12,/history/done_intermediate/msrabi/job_1445062781478_0015_conf.xml_tmp
356,10,2015-10-17 <*> INFO [Thread-110] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
357,6,/history/done_intermediate/msrabi/job_1445062781478_0015.summary
358,6,/history/done_intermediate/msrabi/job_1445062781478_0015_conf.xml
359,6,/history/done_intermediate/msrabi/job_1445062781478_0015-1445067477119-msrabi-pagerank-1445068216511-10-1-SUCCEEDED-default-1445067831801.jhist
360,12,/history/done_intermediate/msrabi/job_1445175094696_0002-1445175179003-msrabi-word+count-1445175914697-10-1-SUCCEEDED-default-1445175187699.jhist_tmp
361,10,2015-10-18 <*> INFO [Thread-123] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
362,12,/history/done_intermediate/msrabi/job_1445175094696_0002_conf.xml_tmp
363,6,/history/done_intermediate/msrabi/job_1445175094696_0002.summary
364,6,/history/done_intermediate/msrabi/job_1445175094696_0002_conf.xml
365,6,/history/done_intermediate/msrabi/job_1445175094696_0002-1445175179003-msrabi-word+count-1445175914697-10-1-SUCCEEDED-default-1445175187699.jhist
366,10,"2015-10-18 21:45:36,276 INFO [Thread-120] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
367,10,2015-10-17 <*> INFO [Thread-34] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
368,20,"<*> <*> WARN [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Unable to parse prior job history, aborting recovery"
369,48,java.io.IOException: Incompatible event log version: null
370,20,<*> <*> WARN [main] org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Could not parse the old history file. Will not have old AMinfos
371,12,/history/done_intermediate/msrabi/job_1445144423722_0023-1445162506952-msrabi-pagerank-1445163783933-10-1-SUCCEEDED-default-1445163429025.jhist_tmp
372,12,/history/done_intermediate/msrabi/job_1445144423722_0023_conf.xml_tmp
373,6,/history/done_intermediate/msrabi/job_1445144423722_0023.summary
374,6,/history/done_intermediate/msrabi/job_1445144423722_0023_conf.xml
375,6,/history/done_intermediate/msrabi/job_1445144423722_0023-1445162506952-msrabi-pagerank-1445163783933-10-1-SUCCEEDED-default-1445163429025.jhist
376,10,2015-10-18 <*> INFO [Thread-110] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
377,5,"2015-10-18 18:10:56,874 ERROR [eventHandlingThread] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Error closing writer for JobID: job_1445144423722_0023"
378,14,"2015-10-18 <*> ERROR [eventHandlingThread] org.apache.hadoop.yarn.YarnUncaughtExceptionHandler: Thread Thread[eventHandlingThread,5,main] threw an Exception."
379,10,2015-10-18 <*> WARN <*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Found jobId <*> to have not been closed. Will close
380,19,2015-10-18 <*> ERROR <*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Error writing History Event: <*>
381,6,java.nio.channels.ClosedChannelException
382,10,2015-10-18 <*> INFO [Thread-581] org.apache.hadoop.service.AbstractService: Service <*> failed in state STOPPED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.nio.channels.ClosedChannelException
383,24,org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.nio.channels.ClosedChannelException
384,5,"2015-10-18 18:10:56,890 WARN [Thread-581] org.apache.hadoop.service.CompositeService: When stopping the service JobHistoryEventHandler : org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.nio.channels.ClosedChannelException"
385,10,"2015-10-18 18:10:56,905 INFO [Thread-581] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
386,9,2015-10-18 <*> INFO <*> org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: <*> <*> ScheduledReds:0 <*> AssignedReds:0 <*> <*> <*> ContRel:0 <*> RackLocal:1
387,12,/history/done_intermediate/msrabi/job_1445087491445_0006-1445091992888-msrabi-word+count-1445093780514-10-1-SUCCEEDED-default-1445092006078.jhist_tmp
388,12,/history/done_intermediate/msrabi/job_1445087491445_0006_conf.xml_tmp
389,6,/history/done_intermediate/msrabi/job_1445087491445_0006.summary
390,6,/history/done_intermediate/msrabi/job_1445087491445_0006_conf.xml
391,6,/history/done_intermediate/msrabi/job_1445087491445_0006-1445091992888-msrabi-word+count-1445093780514-10-1-SUCCEEDED-default-1445092006078.jhist
392,20,2015-10-17 <*> INFO [Thread-78] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
393,5,"2015-10-17 21:50:55,841 ERROR [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Connection retry failed with 4 attempts in 180 seconds"
394,5,"2015-10-17 21:50:55,842 WARN [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Failed to connect to MININT-FNANLI5.fareast.corp.microsoft.com:13562 with 1 map outputs"
395,6,java.net.ConnectException: Connection timed out: connect
396,5,"2015-10-17 21:50:55,848 INFO [fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Reporting fetch failure for attempt_1445087491445_0004_m_000005_0 to jobtracker."
397,5,"2015-10-17 21:51:34,611 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Preempting attempt_1445087491445_0004_r_000000_1000"
398,5,"2015-10-17 21:51:35,614 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent 0.9230769 totalResourceLimit:<memory:1024, vCores:-12> finalMapResourceLimit:<memory:512, vCores:-6> finalReduceResourceLimit:<memory:512, vCores:-6> netScheduledMapResource:<memory:1024, vCores:1> netScheduledReduceResource:<memory:1024, vCores:1>"
399,12,/history/done_intermediate/msrabi/job_1445087491445_0004-1445088243078-msrabi-word+count-1445090594569-13-1-SUCCEEDED-default-1445088253210.jhist_tmp
400,12,/history/done_intermediate/msrabi/job_1445087491445_0004_conf.xml_tmp
401,6,/history/done_intermediate/msrabi/job_1445087491445_0004.summary
402,6,/history/done_intermediate/msrabi/job_1445087491445_0004_conf.xml
403,6,/history/done_intermediate/msrabi/job_1445087491445_0004-1445088243078-msrabi-word+count-1445090594569-13-1-SUCCEEDED-default-1445088253210.jhist
404,10,"2015-10-17 22:03:14,960 INFO [Thread-113] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
405,15,2015-10-17 <*> INFO [Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
406,10,2015-10-17 <*> ERROR [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Error communicating with RM: Resource Manager doesn't recognize AttemptId: <*>
407,12,org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Resource Manager doesn't recognize AttemptId: <*>
408,24,Caused by: <*> Application attempt <*> doesn't exist in ApplicationMasterService cache.
409,20,2015-10-17 <*> INFO <*> <*> <*> notified that <*> <*> false
410,102,2015-10-17 <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: <*> <*> <*> <*> <*> <*> CompletedReds:0 <*> ContRel:2 <*> <*>
411,12,/history/done_intermediate/msrabi/job_1445076437777_0003-1445076558237-msrabi-pagerank-1445077068938-10-1-SUCCEEDED-default-1445076564396.jhist_tmp
412,10,2015-10-17 <*> INFO [Thread-115] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
413,12,/history/done_intermediate/msrabi/job_1445076437777_0003_conf.xml_tmp
414,6,/history/done_intermediate/msrabi/job_1445076437777_0003.summary
415,6,/history/done_intermediate/msrabi/job_1445076437777_0003_conf.xml
416,6,/history/done_intermediate/msrabi/job_1445076437777_0003-1445076558237-msrabi-pagerank-1445077068938-10-1-SUCCEEDED-default-1445076564396.jhist
417,10,2015-10-17 <*> INFO [Thread-96] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
418,5,"2015-10-19 14:26:43,649 FATAL [main] org.apache.hadoop.mapred.Task: Task attempt_1445182159119_0004_m_000004_0 failed : org.apache.hadoop.fs.FSError: java.io.IOException: There is not enough space on the disk"
419,22,2015-10-19 <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: <*> <*> <*> <*> <*> <*> CompletedReds:0 <*> <*> HostLocal:6 <*>
420,70,2015-10-19 <*> <*> [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> java.io.IOException: There is not enough space on the disk
421,48,<*> <*> <*> <*> <*> <*> <*> Diagnostics report from <*> <*> java.io.IOException: There is not enough space on the disk
422,10,2015-10-19 <*> FATAL [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: <*> - failed due to FSError: java.io.IOException: There is not enough space on the disk
423,30,2015-10-19 <*> <*> [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> java.io.IOException: Spill failed
424,15,2015-10-19 <*> INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from <*> Error: java.io.IOException: Spill failed
425,40,"2015-10-19 <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:1024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: <*> }, ] to fast fail map"
426,12,/history/done_intermediate/msrabi/job_1445182159119_0004-1445235687925-msrabi-word+count-1445236895250-10-1-SUCCEEDED-default-1445235702927.jhist_tmp
427,50,2015-10-19 <*> INFO <*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: <*> <*> <*> <*> hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging
428,12,/history/done_intermediate/msrabi/job_1445182159119_0004_conf.xml_tmp
429,6,/history/done_intermediate/msrabi/job_1445182159119_0004.summary
430,6,/history/done_intermediate/msrabi/job_1445182159119_0004_conf.xml
431,6,/history/done_intermediate/msrabi/job_1445182159119_0004-1445235687925-msrabi-word+count-1445236895250-10-1-SUCCEEDED-default-1445235702927.jhist
432,10,2015-10-19 <*> INFO [Thread-137] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
433,12,/history/done_intermediate/msrabi/job_1445087491445_0008-1445091993800-msrabi-word+count-1445093428949-10-1-SUCCEEDED-default-1445092006219.jhist_tmp
434,12,/history/done_intermediate/msrabi/job_1445087491445_0008_conf.xml_tmp
435,6,/history/done_intermediate/msrabi/job_1445087491445_0008.summary
436,6,/history/done_intermediate/msrabi/job_1445087491445_0008_conf.xml
437,6,/history/done_intermediate/msrabi/job_1445087491445_0008-1445091993800-msrabi-word+count-1445093428949-10-1-SUCCEEDED-default-1445092006219.jhist
438,10,2015-10-17 <*> INFO [Thread-24] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
439,20,2015-10-19 <*> INFO [Thread-54] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
440,12,/history/done_intermediate/msrabi/job_1445182159119_0019-1445247552638-msrabi-pagerank-1445248878331-10-1-SUCCEEDED-default-1445248388426.jhist_tmp
441,12,/history/done_intermediate/msrabi/job_1445182159119_0019_conf.xml_tmp
442,6,/history/done_intermediate/msrabi/job_1445182159119_0019.summary
443,6,/history/done_intermediate/msrabi/job_1445182159119_0019_conf.xml
444,6,/history/done_intermediate/msrabi/job_1445182159119_0019-1445247552638-msrabi-pagerank-1445248878331-10-1-SUCCEEDED-default-1445248388426.jhist
445,10,"2015-10-19 18:01:19,195 INFO [Thread-109] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
446,12,/history/done_intermediate/msrabi/job_1445087491445_0007-1445091992751-msrabi-word+count-1445092782902-10-1-SUCCEEDED-default-1445092004218.jhist_tmp
447,12,/history/done_intermediate/msrabi/job_1445087491445_0007_conf.xml_tmp
448,6,/history/done_intermediate/msrabi/job_1445087491445_0007.summary
449,6,/history/done_intermediate/msrabi/job_1445087491445_0007_conf.xml
450,6,/history/done_intermediate/msrabi/job_1445087491445_0007-1445091992751-msrabi-word+count-1445092782902-10-1-SUCCEEDED-default-1445092004218.jhist
451,10,2015-10-17 <*> INFO [Thread-87] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
452,20,2015-10-17 <*> INFO [Thread-54] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
453,12,/history/done_intermediate/msrabi/job_1445062781478_0014-1445067476672-msrabi-pagerank-1445068037828-10-1-SUCCEEDED-default-1445067489454.jhist_tmp
454,12,/history/done_intermediate/msrabi/job_1445062781478_0014_conf.xml_tmp
455,6,/history/done_intermediate/msrabi/job_1445062781478_0014.summary
456,6,/history/done_intermediate/msrabi/job_1445062781478_0014_conf.xml
457,6,/history/done_intermediate/msrabi/job_1445062781478_0014-1445067476672-msrabi-pagerank-1445068037828-10-1-SUCCEEDED-default-1445067489454.jhist
458,10,"2015-10-17 15:47:22,469 INFO [Thread-111] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
459,12,/history/done_intermediate/msrabi/job_1445062781478_0013-1445067474867-msrabi-pagerank-1445068682874-10-1-SUCCEEDED-default-1445068409976.jhist_tmp
460,12,/history/done_intermediate/msrabi/job_1445062781478_0013_conf.xml_tmp
461,6,/history/done_intermediate/msrabi/job_1445062781478_0013.summary
462,6,/history/done_intermediate/msrabi/job_1445062781478_0013_conf.xml
463,6,/history/done_intermediate/msrabi/job_1445062781478_0013-1445067474867-msrabi-pagerank-1445068682874-10-1-SUCCEEDED-default-1445068409976.jhist
464,1933,<*> <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: PendingReds:1 <*> ScheduledReds:0 <*> AssignedReds:0 <*> CompletedReds:0 <*> <*> <*> <*>
465,12,/history/done_intermediate/msrabi/job_1445182159119_0017-1445247551183-msrabi-pagerank-1445247776598-10-1-SUCCEEDED-default-1445247558273.jhist_tmp
466,12,/history/done_intermediate/msrabi/job_1445182159119_0017_conf.xml_tmp
467,6,/history/done_intermediate/msrabi/job_1445182159119_0017.summary
468,6,/history/done_intermediate/msrabi/job_1445182159119_0017_conf.xml
469,6,/history/done_intermediate/msrabi/job_1445182159119_0017-1445247551183-msrabi-pagerank-1445247776598-10-1-SUCCEEDED-default-1445247558273.jhist
470,10,"2015-10-19 17:43:06,004 INFO [Thread-97] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
471,12,/history/done_intermediate/msrabi/job_1445094324383_0005-1445094473081-msrabi-word+count-1445097000193-10-1-SUCCEEDED-default-1445094480534.jhist_tmp
472,12,/history/done_intermediate/msrabi/job_1445094324383_0005_conf.xml_tmp
473,6,/history/done_intermediate/msrabi/job_1445094324383_0005.summary
474,6,/history/done_intermediate/msrabi/job_1445094324383_0005_conf.xml
475,6,/history/done_intermediate/msrabi/job_1445094324383_0005-1445094473081-msrabi-word+count-1445097000193-10-1-SUCCEEDED-default-1445094480534.jhist
476,10,"2015-10-17 23:50:00,974 INFO [Thread-193] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
477,12,/history/done_intermediate/msrabi/job_1445182159119_0005-1445235688984-msrabi-word+count-1445237386355-10-1-SUCCEEDED-default-1445236911535.jhist_tmp
478,12,/history/done_intermediate/msrabi/job_1445182159119_0005_conf.xml_tmp
479,6,/history/done_intermediate/msrabi/job_1445182159119_0005.summary
480,6,/history/done_intermediate/msrabi/job_1445182159119_0005_conf.xml
481,6,/history/done_intermediate/msrabi/job_1445182159119_0005-1445235688984-msrabi-word+count-1445237386355-10-1-SUCCEEDED-default-1445236911535.jhist
482,10,"2015-10-19 14:49:47,277 INFO [Thread-101] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
483,25,2015-10-18 <*> INFO [communication thread] org.apache.hadoop.mapred.Task: Process Thread Dump: Communication exception
484,30,<*> active threads
485,24,Thread 21 (SpillThread):
486,378,State: <*>
487,378,Blocked count: <*>
488,378,Waited count: <*>
489,108,Waiting on <*>
490,378,Stack:
491,108,sun.misc.Unsafe.park(Native Method)
492,48,java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)
493,48,java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)
494,24,org.apache.hadoop.mapred.MapTask$MapOutputBuffer$SpillThread.run(MapTask.java:1521)
495,30,Thread 20 <*>
496,30,java.lang.Thread.sleep(Native Method)
497,30,org.apache.hadoop.hdfs.PeerCache.run(PeerCache.java:244)
498,30,org.apache.hadoop.hdfs.PeerCache.access$000(PeerCache.java:41)
499,30,org.apache.hadoop.hdfs.PeerCache$1.run(PeerCache.java:119)
500,144,java.lang.Thread.run(Thread.java:724)
501,30,Thread 16 (communication thread):
502,180,<*> Method)
503,30,sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:174)
504,30,sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:139)
505,30,org.apache.hadoop.util.ReflectionUtils.printThreadInfo(ReflectionUtils.java:165)
506,30,org.apache.hadoop.util.ReflectionUtils.logThreadInfo(ReflectionUtils.java:219)
507,30,org.apache.hadoop.mapred.Task$TaskReporter.run(Task.java:760)
508,30,Thread 15 (Thread for syncLogs):
509,60,java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:226)
510,30,java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2082)
511,30,java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1090)
512,30,java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:807)
513,84,java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1068)
514,84,java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)
515,84,java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
516,30,Thread 13 (IPC Parameter Sending Thread #0):
517,30,java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
518,30,java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:359)
519,30,java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:942)
520,30,Thread 11 (Timer for 'MapTask' metrics system):
521,30,java.util.TimerThread.mainLoop(Timer.java:552)
522,30,java.util.TimerThread.run(Timer.java:505)
523,30,Thread 10 (Thread-1):
524,30,sun.net.dns.ResolverConfigurationImpl$AddressChangeListener.run(ResolverConfigurationImpl.java:142)
525,30,Thread 5 (Attach Listener):
526,30,Thread 4 (Signal Dispatcher):
527,30,Thread 3 (Finalizer):
528,30,java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:135)
529,30,java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:151)
530,30,java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:189)
531,30,Thread 2 (Reference Handler):
532,30,java.lang.Object.wait(Object.java:503)
533,30,java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133)
534,30,Thread 1 (main):
535,24,sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(WindowsSelectorImpl.java:296)
536,24,sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(WindowsSelectorImpl.java:278)
537,24,sun.nio.ch.WindowsSelectorImpl.doSelect(WindowsSelectorImpl.java:159)
538,24,sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:87)
539,24,sun.nio.ch.SelectorImpl.select(SelectorImpl.java:98)
540,24,org.apache.hadoop.net.SocketIOWithTimeout$SelectorPool.select(SocketIOWithTimeout.java:335)
541,24,org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:157)
542,24,org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
543,24,org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.readChannelFully(PacketReceiver.java:258)
544,24,org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:209)
545,24,org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:171)
546,24,org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:102)
547,24,org.apache.hadoop.hdfs.RemoteBlockReader2.readNextPacket(RemoteBlockReader2.java:186)
548,24,org.apache.hadoop.hdfs.RemoteBlockReader2.read(RemoteBlockReader2.java:146)
549,24,org.apache.hadoop.hdfs.DFSInputStream$ByteArrayStrategy.doRead(DFSInputStream.java:693)
550,24,org.apache.hadoop.hdfs.DFSInputStream.readBuffer(DFSInputStream.java:749)
551,24,org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:806)
552,24,org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:847)
553,24,java.io.DataInputStream.read(DataInputStream.java:100)
554,25,"2015-10-18 <*> WARN [communication thread] org.apache.hadoop.mapred.Task: Last retry, killing <*>"
555,5,"2015-10-18 21:39:34,868 INFO [main] org.apache.hadoop.hdfs.DFSClient: Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073742989_2201 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073742989_2201 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010 10.86.169.121:50010. Will get new block locations from namenode and retry..."
556,24,Thread <*> (Readahead Thread <*>
557,24,java.util.concurrent.ArrayBlockingQueue.take(ArrayBlockingQueue.java:374)
558,6,java.util.zip.CRC32.update(CRC32.java:65)
559,6,org.apache.hadoop.util.DataChecksum.update(DataChecksum.java:265)
560,6,org.apache.hadoop.mapred.IFileOutputStream.write(IFileOutputStream.java:87)
561,6,org.apache.hadoop.mapred.IFileOutputStream.write(IFileOutputStream.java:94)
562,6,org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:50)
563,6,java.io.DataOutputStream.writeByte(DataOutputStream.java:153)
564,6,org.apache.hadoop.io.WritableUtils.writeVLong(WritableUtils.java:273)
565,6,org.apache.hadoop.io.WritableUtils.writeVInt(WritableUtils.java:253)
566,6,org.apache.hadoop.mapred.IFile$Writer.append(IFile.java:214)
567,6,org.apache.hadoop.mapred.Task$CombineOutputCollector.collect(Task.java:1313)
568,6,org.apache.hadoop.mapred.Task$NewCombinerRunner$OutputConverter.write(Task.java:1630)
569,6,org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
570,6,org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.write(WrappedReducer.java:105)
571,6,org.apache.hadoop.examples.WordCount$IntSumReducer.reduce(WordCount.java:64)
572,6,org.apache.hadoop.examples.WordCount$IntSumReducer.reduce(WordCount.java:52)
573,6,org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
574,6,org.apache.hadoop.mapred.Task$NewCombinerRunner.combine(Task.java:1651)
575,6,org.apache.hadoop.mapred.MapTask$MapOutputBuffer.mergeParts(MapTask.java:1911)
576,6,org.apache.hadoop.mapred.MapTask$MapOutputBuffer.flush(MapTask.java:1504)
577,5,"2015-10-19 14:26:44,223 INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent 0.7 totalResourceLimit:<memory:9216, vCores:-18> finalMapResourceLimit:<memory:4608, vCores:-9> finalReduceResourceLimit:<memory:4608, vCores:-9> netScheduledMapResource:<memory:7168, vCores:7> netScheduledReduceResource:<memory:1024, vCores:1>"
578,12,/history/done_intermediate/msrabi/job_1445182159119_0003-1445235687728-msrabi-word+count-1445236974655-10-1-SUCCEEDED-default-1445235698649.jhist_tmp
579,12,/history/done_intermediate/msrabi/job_1445182159119_0003_conf.xml_tmp
580,6,/history/done_intermediate/msrabi/job_1445182159119_0003.summary
581,6,/history/done_intermediate/msrabi/job_1445182159119_0003_conf.xml
582,6,/history/done_intermediate/msrabi/job_1445182159119_0003-1445235687728-msrabi-word+count-1445236974655-10-1-SUCCEEDED-default-1445235698649.jhist
583,10,2015-10-19 <*> INFO [Thread-141] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
584,12,/history/done_intermediate/msrabi/job_1445062781478_0019-1445071656627-msrabi-pagerank-1445073067476-10-1-SUCCEEDED-default-1445072789649.jhist_tmp
585,12,/history/done_intermediate/msrabi/job_1445062781478_0019_conf.xml_tmp
586,6,/history/done_intermediate/msrabi/job_1445062781478_0019.summary
587,6,/history/done_intermediate/msrabi/job_1445062781478_0019_conf.xml
588,6,/history/done_intermediate/msrabi/job_1445062781478_0019-1445071656627-msrabi-pagerank-1445073067476-10-1-SUCCEEDED-default-1445072789649.jhist
589,10,2015-10-17 <*> INFO [Thread-100] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
590,12,/history/done_intermediate/msrabi/job_1445182159119_0020-1445247554890-msrabi-pagerank-1445248864486-10-1-SUCCEEDED-default-1445248046659.jhist_tmp
591,12,/history/done_intermediate/msrabi/job_1445182159119_0020_conf.xml_tmp
592,6,/history/done_intermediate/msrabi/job_1445182159119_0020.summary
593,6,/history/done_intermediate/msrabi/job_1445182159119_0020_conf.xml
594,6,/history/done_intermediate/msrabi/job_1445182159119_0020-1445247554890-msrabi-pagerank-1445248864486-10-1-SUCCEEDED-default-1445248046659.jhist
595,10,"2015-10-19 18:01:06,877 INFO [Thread-114] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
596,12,/history/done_intermediate/msrabi/job_1445144423722_0022-1445162506766-msrabi-pagerank-1445163053703-10-1-SUCCEEDED-default-1445162512818.jhist_tmp
597,12,/history/done_intermediate/msrabi/job_1445144423722_0022_conf.xml_tmp
598,6,/history/done_intermediate/msrabi/job_1445144423722_0022.summary
599,6,/history/done_intermediate/msrabi/job_1445144423722_0022_conf.xml
600,6,/history/done_intermediate/msrabi/job_1445144423722_0022-1445162506766-msrabi-pagerank-1445163053703-10-1-SUCCEEDED-default-1445162512818.jhist
601,10,2015-10-18 <*> INFO [Thread-115] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
602,10,2015-10-18 <*> INFO [Thread-125] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
603,12,java.net.ConnectException: Connection refused: no further information
604,5,"2015-10-17 21:49:58,486 WARN [main] org.apache.hadoop.hdfs.DFSClient: Failed to connect to /10.86.169.121:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection refused: no further information"
605,12,/history/done_intermediate/msrabi/job_1445087491445_0005-1445088243632-msrabi-word+count-1445090485571-13-1-SUCCEEDED-default-1445089672614.jhist_tmp
606,12,/history/done_intermediate/msrabi/job_1445087491445_0005_conf.xml_tmp
607,6,/history/done_intermediate/msrabi/job_1445087491445_0005.summary
608,6,/history/done_intermediate/msrabi/job_1445087491445_0005_conf.xml
609,6,/history/done_intermediate/msrabi/job_1445087491445_0005-1445088243632-msrabi-word+count-1445090485571-13-1-SUCCEEDED-default-1445089672614.jhist
610,10,2015-10-17 <*> INFO [Thread-147] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
611,12,/history/done_intermediate/msrabi/job_1445175094696_0001-1445175178663-msrabi-word+count-1445175930238-10-1-SUCCEEDED-default-1445175188000.jhist_tmp
612,12,/history/done_intermediate/msrabi/job_1445175094696_0001_conf.xml_tmp
613,10,2015-10-18 <*> INFO [Thread-128] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
614,6,/history/done_intermediate/msrabi/job_1445175094696_0001.summary
615,6,/history/done_intermediate/msrabi/job_1445175094696_0001_conf.xml
616,6,/history/done_intermediate/msrabi/job_1445175094696_0001-1445175178663-msrabi-word+count-1445175930238-10-1-SUCCEEDED-default-1445175188000.jhist
617,10,2015-10-18 <*> INFO [Thread-123] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
618,81,2015-10-19 <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: PendingReds:0 <*> <*> <*> <*> <*> <*> <*> ContRel:1 <*> <*>
619,12,/history/done_intermediate/msrabi/job_1445182159119_0013-1445240988628-msrabi-pagerank-1445241437667-10-1-SUCCEEDED-default-1445240997639.jhist_tmp
620,12,/history/done_intermediate/msrabi/job_1445182159119_0013_conf.xml_tmp
621,6,/history/done_intermediate/msrabi/job_1445182159119_0013.summary
622,6,/history/done_intermediate/msrabi/job_1445182159119_0013_conf.xml
623,6,/history/done_intermediate/msrabi/job_1445182159119_0013-1445240988628-msrabi-pagerank-1445241437667-10-1-SUCCEEDED-default-1445240997639.jhist
624,10,2015-10-19 <*> INFO [Thread-108] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
625,12,/history/done_intermediate/msrabi/job_1445144423722_0021-1445162505377-msrabi-pagerank-1445162724640-10-1-SUCCEEDED-default-1445162511808.jhist_tmp
626,25,2015-10-18 <*> INFO [Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: <*> <*> <*> <*> hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging
627,12,/history/done_intermediate/msrabi/job_1445144423722_0021_conf.xml_tmp
628,6,/history/done_intermediate/msrabi/job_1445144423722_0021.summary
629,6,/history/done_intermediate/msrabi/job_1445144423722_0021_conf.xml
630,6,/history/done_intermediate/msrabi/job_1445144423722_0021-1445162505377-msrabi-pagerank-1445162724640-10-1-SUCCEEDED-default-1445162511808.jhist
631,10,"2015-10-18 18:05:48,719 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
632,12,/history/done_intermediate/msrabi/job_1445182159119_0015-1445240991382-msrabi-pagerank-1445241754459-10-1-SUCCEEDED-default-1445241361172.jhist_tmp
633,12,/history/done_intermediate/msrabi/job_1445182159119_0015_conf.xml_tmp
634,6,/history/done_intermediate/msrabi/job_1445182159119_0015.summary
635,6,/history/done_intermediate/msrabi/job_1445182159119_0015_conf.xml
636,6,/history/done_intermediate/msrabi/job_1445182159119_0015-1445240991382-msrabi-pagerank-1445241754459-10-1-SUCCEEDED-default-1445241361172.jhist
637,10,"2015-10-19 16:02:35,646 INFO [Thread-115] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
638,12,/history/done_intermediate/msrabi/job_1445175094696_0005-1445175181929-msrabi-word+count-1445176478000-10-1-SUCCEEDED-default-1445175951295.jhist_tmp
639,12,/history/done_intermediate/msrabi/job_1445175094696_0005_conf.xml_tmp
640,6,/history/done_intermediate/msrabi/job_1445175094696_0005.summary
641,6,/history/done_intermediate/msrabi/job_1445175094696_0005_conf.xml
642,6,/history/done_intermediate/msrabi/job_1445175094696_0005-1445175181929-msrabi-word+count-1445176478000-10-1-SUCCEEDED-default-1445175951295.jhist
643,10,"2015-10-18 21:54:38,593 INFO [Thread-106] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
644,5,"2015-10-17 16:53:31,853 INFO [IPC Server handler 27 on 19061] org.apache.hadoop.mapred.TaskAttemptListenerImpl: MapCompletionEvents reques"
645,10,2015-10-19 <*> INFO [Thread-56] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
646,12,/history/done_intermediate/msrabi/job_1445182159119_0018-1445247551536-msrabi-pagerank-1445249001110-10-1-SUCCEEDED-default-1445248396740.jhist_tmp
647,12,/history/done_intermediate/msrabi/job_1445182159119_0018_conf.xml_tmp
648,6,/history/done_intermediate/msrabi/job_1445182159119_0018.summary
649,6,/history/done_intermediate/msrabi/job_1445182159119_0018_conf.xml
650,6,/history/done_intermediate/msrabi/job_1445182159119_0018-1445247551536-msrabi-pagerank-1445249001110-10-1-SUCCEEDED-default-1445248396740.jhist
651,10,"2015-10-19 18:03:21,594 INFO [Thread-117] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
652,12,/history/done_intermediate/msrabi/job_1445182159119_0012-1445240987944-msrabi-pagerank-1445241196006-10-1-SUCCEEDED-default-1445240996264.jhist_tmp
653,12,/history/done_intermediate/msrabi/job_1445182159119_0012_conf.xml_tmp
654,6,/history/done_intermediate/msrabi/job_1445182159119_0012.summary
655,6,/history/done_intermediate/msrabi/job_1445182159119_0012_conf.xml
656,6,/history/done_intermediate/msrabi/job_1445182159119_0012-1445240987944-msrabi-pagerank-1445241196006-10-1-SUCCEEDED-default-1445240996264.jhist
657,10,"2015-10-19 15:53:16,740 INFO [Thread-94] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
658,12,/history/done_intermediate/msrabi/job_1445087491445_0001-1445088243078-msrabi-word+count-1445089632420-13-1-SUCCEEDED-default-1445088252553.jhist_tmp
659,12,/history/done_intermediate/msrabi/job_1445087491445_0001_conf.xml_tmp
660,10,2015-10-17 <*> INFO [Thread-163] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
661,6,/history/done_intermediate/msrabi/job_1445087491445_0001.summary
662,6,/history/done_intermediate/msrabi/job_1445087491445_0001_conf.xml
663,6,/history/done_intermediate/msrabi/job_1445087491445_0001-1445088243078-msrabi-word+count-1445089632420-13-1-SUCCEEDED-default-1445088252553.jhist
664,10,"2015-10-17 21:47:31,749 INFO [Thread-158] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
665,12,<*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> <*> java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
666,10,"2015-10-18 21:45:16,048 INFO [Thread-626] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
667,12,/history/done_intermediate/msrabi/job_1445175094696_0003-1445175179225-msrabi-word+count-1445176599683-10-1-SUCCEEDED-default-1445175186428.jhist_tmp
668,12,/history/done_intermediate/msrabi/job_1445175094696_0003_conf.xml_tmp
669,6,/history/done_intermediate/msrabi/job_1445175094696_0003.summary
670,6,/history/done_intermediate/msrabi/job_1445175094696_0003_conf.xml
671,6,/history/done_intermediate/msrabi/job_1445175094696_0003-1445175179225-msrabi-word+count-1445176599683-10-1-SUCCEEDED-default-1445175186428.jhist
672,10,2015-10-18 <*> INFO [Thread-81] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
673,12,/history/done_intermediate/msrabi/job_1445062781478_0018-1445071655606-msrabi-pagerank-1445073306943-10-1-SUCCEEDED-default-1445071661919.jhist_tmp
674,12,/history/done_intermediate/msrabi/job_1445062781478_0018_conf.xml_tmp
675,6,/history/done_intermediate/msrabi/job_1445062781478_0018.summary
676,6,/history/done_intermediate/msrabi/job_1445062781478_0018_conf.xml
677,6,/history/done_intermediate/msrabi/job_1445062781478_0018-1445071655606-msrabi-pagerank-1445073306943-10-1-SUCCEEDED-default-1445071661919.jhist
678,10,2015-10-17 <*> INFO [Thread-79] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
679,5,"2015-10-17 23:12:21,506 WARN [IPC Server handler 29 on 58622] org.apache.hadoop.ipc.Server: IPC Server handler 29 on 58622, call statusUpdate(attempt_1445094324383_0003_m_000000_0, org.apache.hadoop.mapred.MapTaskStatus@cdcdbf7), rpc version=2, client version=19, methodsFingerPrint=937413979 from 10.86.169.121:52490 Call#68 Retry#0: output error"
680,5,"2015-10-17 23:12:21,506 INFO [IPC Server handler 29 on 58622] org.apache.hadoop.ipc.Server: IPC Server handler 29 on 58622 caught an exception"
681,12,/history/done_intermediate/msrabi/job_1445094324383_0003-1445094473124-msrabi-word+count-1445095679409-10-1-SUCCEEDED-default-1445094480842.jhist_tmp
682,12,/history/done_intermediate/msrabi/job_1445094324383_0003_conf.xml_tmp
683,6,/history/done_intermediate/msrabi/job_1445094324383_0003.summary
684,6,/history/done_intermediate/msrabi/job_1445094324383_0003_conf.xml
685,6,/history/done_intermediate/msrabi/job_1445094324383_0003-1445094473124-msrabi-word+count-1445095679409-10-1-SUCCEEDED-default-1445094480842.jhist
686,10,"2015-10-17 23:28:02,174 INFO [Thread-138] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>"
687,12,/history/done_intermediate/msrabi/job_1445062781478_0012-1445067474738-msrabi-pagerank-1445068175962-10-1-SUCCEEDED-default-1445067485173.jhist_tmp
688,10,2015-10-17 <*> INFO [Thread-125] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
689,12,/history/done_intermediate/msrabi/job_1445062781478_0012_conf.xml_tmp
690,6,/history/done_intermediate/msrabi/job_1445062781478_0012.summary
691,6,/history/done_intermediate/msrabi/job_1445062781478_0012_conf.xml
692,6,/history/done_intermediate/msrabi/job_1445062781478_0012-1445067474738-msrabi-pagerank-1445068175962-10-1-SUCCEEDED-default-1445067485173.jhist
693,10,2015-10-17 <*> INFO [Thread-93] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
694,12,/history/done_intermediate/msrabi/job_1445094324383_0002-1445094473189-msrabi-word+count-1445097067469-10-1-SUCCEEDED-default-1445095245355.jhist_tmp
695,12,/history/done_intermediate/msrabi/job_1445094324383_0002_conf.xml_tmp
696,6,/history/done_intermediate/msrabi/job_1445094324383_0002.summary
697,6,/history/done_intermediate/msrabi/job_1445094324383_0002_conf.xml
698,6,/history/done_intermediate/msrabi/job_1445094324383_0002-1445094473189-msrabi-word+count-1445097067469-10-1-SUCCEEDED-default-1445095245355.jhist
699,10,2015-10-17 <*> INFO [Thread-152] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
700,236,2015-10-19 <*> INFO [RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: PendingReds:0 <*> <*> <*> <*> <*> CompletedReds:0 <*> ContRel:2 <*> <*>
701,5,"2015-10-19 18:08:58,624 INFO [IPC Server handler 28 on 55796] org.apache.hadoop.map"
702,12,/history/done_intermediate/msrabi/job_1445087491445_0003-1445088243334-msrabi-word+count-1445089655963-13-1-SUCCEEDED-default-1445088258186.jhist_tmp
703,12,/history/done_intermediate/msrabi/job_1445087491445_0003_conf.xml_tmp
704,6,/history/done_intermediate/msrabi/job_1445087491445_0003.summary
705,6,/history/done_intermediate/msrabi/job_1445087491445_0003_conf.xml
706,6,/history/done_intermediate/msrabi/job_1445087491445_0003-1445088243334-msrabi-word+count-1445089655963-13-1-SUCCEEDED-default-1445088258186.jhist
707,10,2015-10-17 <*> INFO [Thread-159] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
708,978,org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
709,978,org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
710,1295,org.apache.hadoop.metrics2.impl.MetricsSystemImpl: <*> metrics system <*>
711,909,org.apache.hadoop.mapred.YarnChild: Executing with tokens:
712,909,"org.apache.hadoop.mapred.YarnChild: Kind: mapreduce.job, Service: <*> Ident: <*>"
713,909,org.apache.hadoop.mapred.YarnChild: Sleeping for 0ms before retrying again. Got null now.
714,907,org.apache.hadoop.mapred.YarnChild: mapreduce.cluster.local.dir for child: <*>
715,963,"org.apache.hadoop.conf.Configuration.deprecation: <*> is deprecated. Instead, use <*>"
716,905,org.apache.hadoop.yarn.util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.
717,905,org.apache.hadoop.mapred.Task: Using ResourceCalculatorProcessTree : <*>
718,71,org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: <*>
719,71,"org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: <*> <*> <*> ioSortFactor=10, memToMemMergeOutputsThreshold=10"
720,71,[EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: <*> Thread started: EventFetcher for fetching Map Completion Events
721,472,<*> org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Assigning <*> with <*> to <*>
722,472,<*> org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: assigned <*> of <*> to <*> to <*>
723,414,[EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: <*> Got <*> new map-outputs
724,469,<*> org.apache.hadoop.mapreduce.task.reduce.Fetcher: for <*> sent hash and received reply
725,667,<*> org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: <*> Shuffling to disk since <*> is greater than maxSingleShuffleLimit <*>
726,664,<*> org.apache.hadoop.mapreduce.task.reduce.Fetcher: <*> about to shuffle output of map <*> decomp: <*> len: <*> to DISK
727,649,<*> org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput: Read <*> bytes from map-output for <*>
728,455,<*> org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: <*> freed by <*> in <*>
729,57,[EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.EventFetcher: <*> <*> <*> <*>
730,56,org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 0 in-memory map-outputs and <*> on-disk map-outputs
731,56,"org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging <*> files, <*> bytes from disk"
732,56,"org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce"
733,678,org.apache.hadoop.mapred.Merger: Merging <*> sorted segments
734,678,"org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with <*> segments left of total size: <*> bytes"
735,625,org.apache.hadoop.mapred.Task: <*> is done. And is in the process of committing
736,48,org.apache.hadoop.mapred.Task: Task <*> is allowed to commit now
737,48,org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task <*> to <*>
738,616,org.apache.hadoop.mapred.Task: Task <*> done.
739,317,org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping <*> metrics system...
740,317,org.apache.hadoop.metrics2.impl.MetricsSystemImpl: <*> metrics system shutdown complete.
741,834,org.apache.hadoop.mapred.MapTask: Processing split: <*>
742,5542,org.apache.hadoop.mapred.MapTask: (EQUATOR) <*> kvi <*>
743,834,org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
744,834,org.apache.hadoop.mapred.MapTask: soft limit at 83886080
745,1668,org.apache.hadoop.mapred.MapTask: <*> = <*> <*> = <*>
746,834,org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
747,5339,org.apache.hadoop.mapred.MapTask: Spilling map output
748,10678,org.apache.hadoop.mapred.MapTask: <*> = <*> <*> = <*> <*> = <*>
749,5204,org.apache.hadoop.mapred.MapTask: Finished spill <*>
750,4579,org.apache.hadoop.mapred.MapTask: (RESET) equator <*> kv <*> kvi <*>
751,644,org.apache.hadoop.mapred.MapTask: Starting flush of map output
752,69,org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Created MRAppMaster for application <*>
753,69,org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Executing with tokens:
754,69,"org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Kind: YARN_AM_RM_TOKEN, Service: , Ident: (appAttemptId { application_id { id: <*> cluster_timestamp: <*> } attemptId: <*> } keyId: <*>"
755,69,org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Using mapred newApiCommitter.
756,69,org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter set in config null
757,69,org.apache.hadoop.mapreduce.v2.app.MRAppMaster: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
758,621,org.apache.hadoop.yarn.event.AsyncDispatcher: Registering class <*> for class <*>
759,226,org.apache.hadoop.mapreduce.v2.jobhistory.JobHistoryUtils: Default file system [hdfs://msra-sa-41:9000]
760,69,org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Emitting job history data to the timeline server is not enabled
761,69,org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Adding job token for <*> to jobTokenSecretManager
762,69,org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Not uberizing <*> because: not enabled; too many maps; too much input;
763,69,org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Input size for job <*> = <*> Number of splits = <*>
764,69,org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: Number of reduces for job <*> = 1
765,69,org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: <*> Transitioned from NEW to INITED
766,69,"org.apache.hadoop.mapreduce.v2.app.MRAppMaster: MRAppMaster launching normal, non-uberized, multi-container job <*>"
767,138,org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
768,138,[Socket Reader #1 for port <*> org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port <*>
769,69,org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl: Adding protocol org.apache.hadoop.mapreduce.v2.api.MRClientProtocolPB to the server
770,69,org.apache.hadoop.mapreduce.v2.app.client.MRClientService: Instantiated MRClientService at <*>
771,186,[IPC Server Responder] org.apache.hadoop.ipc.Server: <*> <*> <*> <*>
772,186,[IPC Server listener on <*> org.apache.hadoop.ipc.Server: <*> <*> <*> <*> <*> <*>
773,69,org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
774,69,org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.mapreduce is not defined
775,69,org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
776,138,org.apache.hadoop.http.HttpServer2: Added filter AM_PROXY_FILTER (class=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter) to context <*>
777,138,org.apache.hadoop.http.HttpServer2: adding path spec: <*>
778,69,org.apache.hadoop.http.HttpServer2: Jetty bound to port <*>
779,69,org.mortbay.log: jetty-6.1.26
780,69,org.mortbay.log: Extract jar:file:/D:/hadoop-2.6.0-localbox/share/hadoop/yarn/hadoop-yarn-common-2.6.0-SNAPSHOT.jar!/webapps/mapreduce to <*>
781,69,org.mortbay.log: Started <*>
782,69,org.apache.hadoop.yarn.webapp.WebApps: Web app /mapreduce started at <*>
783,69,org.apache.hadoop.yarn.webapp.WebApps: Registered webapp guice modules
784,974,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: <*> <*>
785,69,org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: nodeBlacklistingEnabled:true
786,138,org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: <*> is <*>
787,69,org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at <*>
788,69,"org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: maxContainerCapability: <memory:8192, vCores:32>"
789,69,org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: queue: default
790,69,org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Upper limit on the thread pool size is 500
791,69,org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: yarn.client.max-cached-nodemanagers-proxies : 0
792,234,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: <*> Transitioned from <*> to <*>
793,332,[CommitterEvent Processor <*> org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Processing the event EventType: <*>
794,3034,[AsyncDispatcher event handler] org.apache.hadoop.yarn.util.RackResolver: Resolved <*> to /default-rack
795,6917,[AsyncDispatcher event handler] <*> <*> <*> Transitioned from <*> to <*>
796,134,<*> org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> vCores:1>
797,69,org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Event Writer setup for JobId: <*> File: <*>
798,333,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: <*> <*> <*> <*> <*> <*> CompletedReds:0 <*> ContRel:0 <*> RackLocal:0
799,899,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: getResources() for <*> <*> release= <*> <*> <*> <*> <*> <*>
800,5848,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*> <*>
801,3841,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold not met. completedMapsForReduceSlowstart 1
802,906,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigned container <*> to <*>
803,138,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: The <*> file on the remote FS is <*>
804,69,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Adding #0 tokens and #1 secret keys for NM use for launching container
805,138,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: <*> <*> <*> <*> <*>
806,1744,[ContainerLauncher <*> org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Processing the event EventType: <*> for container <*> taskAttempt <*>
807,1744,[ContainerLauncher <*> org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: <*> <*>
808,1744,[ContainerLauncher <*> org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : <*>
809,906,[ContainerLauncher <*> org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: Shuffle port returned by ContainerManager for <*> : 13562
810,1033,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: TaskAttempt: using containerId: <*> on NM: <*>
811,962,[Socket Reader #1 for port <*> SecurityLogger.org.apache.hadoop.ipc.Server: Auth successful for <*> (auth:SIMPLE)
812,902,[IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: JVM with ID : <*> asked for a task
813,466,[IPC Server handler <*> on 61553] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
814,605,[IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: Done acknowledgement from <*>
815,701,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Task succeeded with attempt <*>
816,748,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: <*> <*> <*> <*>
817,65,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Reduce slow start threshold reached. Scheduling reduces.
818,43,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: All maps assigned. Ramping up all remaining reduces:1
819,733,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from <*> Container killed by the ApplicationMaster.
820,592,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> <*> <*>
821,18143,[IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> from <*> <*> <*> <*> <*>
822,3,[IPC Server handler <*> on 61553] <*> <*> <*> <*> <*> <*>
823,47,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: <*> given a go for committing the task output.
824,77,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: <*> <*> ScheduledReds:0 AssignedMaps:0 <*> <*> <*> <*> ContRel:0 <*> <*>
825,50,<*> org.apache.hadoop.mapreduce.v2.app.MRAppMaster: We are finishing cleanly so this is the last retry
826,104,<*> org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Notify <*> isAMLastRetry: <*>
827,2,[Thread-105] <*> <*> notified that <*> <*> true
828,52,<*> org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Calling stop for all the services
829,52,<*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopping JobHistoryEventHandler. Size of the outstanding queue size is <*>
830,88,org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying <*> to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging
831,88,org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copied to done location: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging
832,132,org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Moved tmp to done: hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging
833,48,<*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Stopped JobHistoryEventHandler. super.stop()
834,48,<*> org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Setting job diagnostics to
835,48,<*> org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: History url is <*>
836,45,<*> org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Waiting for application to be successfully unregistered.
837,2,<*> org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 <*> <*> <*> AssignedReds:0 <*> <*> ContAlloc:11 <*> <*> <*>
838,45,<*> org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Deleting staging directory hdfs://msra-sa-41:9000 <*>
839,48,<*> org.apache.hadoop.ipc.Server: Stopping server on <*>
840,48,[TaskHeartbeatHandler PingChecker] org.apache.hadoop.mapreduce.v2.app.TaskHeartbeatHandler: TaskHeartbeatHandler thread interrupted
841,4,org.apache.hadoop.mapred.Task: Failure sending status update: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: <*> destination host is: <*>
842,44,[communication thread] org.apache.hadoop.mapred.Task: Communication exception: java.io.IOException: Failed on local exception: java.io.IOException: An existing connection was forcibly closed by the remote host; Host Details : local host is: <*> destination host is: <*>
843,186,org.apache.hadoop.ipc.Client: Retrying connect to server: <*> Already tried <*> time(s); maxRetries=45
844,1121,[communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: <*> Already tried <*> time(s); maxRetries=45
845,16,org.apache.hadoop.hdfs.BlockReaderFactory: I/O error constructing remote block reader.
846,10,"org.apache.hadoop.hdfs.DFSClient: Failed to connect to <*> for block, add to deadNodes and continue. java.net.NoRouteToHostException: No route to host: no further information"
847,5,"org.apache.hadoop.hdfs.DFSClient: Could not obtain <*> from any node: java.io.IOException: No live nodes contain block <*> after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010. Will get new block locations from namenode and retry..."
848,6,"org.apache.hadoop.hdfs.DFSClient: DFS chooseDataNode: got # 1 IOException, will wait for <*> msec."
849,8,org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
850,3,org.apache.hadoop.hdfs.DFSClient: DFS Read
851,2,org.apache.hadoop.mapred.YarnChild: Exception running child : java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
852,6,org.apache.hadoop.mapred.Task: Runnning cleanup for the task
853,2,org.apache.hadoop.mapred.YarnChild: Exception cleaning up: java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
854,263,[RMCommunicator Allocator] org.apache.hadoop.yarn.util.RackResolver: Resolved <*> to /default-rack
855,302,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: PendingReds:1 <*> ScheduledReds:0 <*> <*> <*> CompletedReds:0 <*> <*> <*> <*>
856,299,[IPC Server handler <*> on 62270] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
857,12,"[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Cannot assign container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:1024, vCores:1>, Priority: <*> Token: Token { kind: ContainerToken, service: <*> }, ] for a map as either container memory less than required <memory:1024, vCores:1> or no pending map tasks - maps.isEmpty=true"
858,19,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Container complete event for unknown container id <*>
859,168,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: PendingReds:0 <*> <*> <*> <*> CompletedMaps:1 CompletedReds:0 <*> <*> <*> <*>
860,255,[DefaultSpeculator background processing] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: DefaultSpeculator.addSpeculativeAttempt -- we are speculating <*>
861,255,[DefaultSpeculator background processing] org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator: We launched 1 speculations. Sleeping 15000 milliseconds.
862,194,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Scheduling a redundant attempt for task <*>
863,5304,<*> org.apache.hadoop.ipc.Client: Address change detected. Old: <*> New: <*>
864,1420,[LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for for <*> seconds. Will retry shortly ...
865,9,"[ResponseProcessor for block <*> org.apache.hadoop.hdfs.DFSClient: Slow ReadProcessor read fields took <*> (threshold=30000ms); ack: seqno: -2 status: SUCCESS status: downstreamAckTimeNanos: 0, targets: <*> <*>"
866,14,[ResponseProcessor for block <*> org.apache.hadoop.hdfs.DFSClient: DFSOutputStream ResponseProcessor exception for block <*>
867,14,java.io.IOException: Bad response for block <*> from datanode <*>
868,14,[DataStreamer for file <*> block <*> org.apache.hadoop.hdfs.DFSClient: Error Recovery for block <*> in pipeline <*> <*> bad datanode <*>
869,2,[DataStreamer for file <*> block <*> org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception
870,479,[RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:8030 New: msra-sa-41:8030
871,479,"[RMCommunicator Allocator] org.apache.hadoop.ipc.Client: Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
872,2,[CommitterEvent Processor <*> org.apache.hadoop.ipc.Client: Address change detected. Old: msra-sa-41/10.190.173.170:9000 New: msra-sa-41:9000
873,2,[CommitterEvent Processor <*> org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler: Task cleanup failed for attempt <*>
874,2,org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Error writing History Event: <*>
875,3,"org.apache.hadoop.yarn.YarnUncaughtExceptionHandler: Thread Thread[eventHandlingThread,5,main] threw an Exception."
876,10,[Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerRequestor: <*> failures on node <*>
877,10,[Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Added <*> to list of failed maps
878,3,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Could not contact RM after 360000 milliseconds.
879,3,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Error communicating with RM: Could not contact RM after 360000 milliseconds.
880,3,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: <*> Transitioned from RUNNING to
881,2,[Thread-560] <*> <*> notified that <*> <*> true
882,6,"<*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: In stop, writing event <*>"
883,2,[Thread-560] org.apache.hadoop.service.AbstractService: Service <*> failed in state STOPPED; cause: org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected.
884,1,[Thread-560] org.apache.hadoop.service.CompositeService: When stopping the service JobHistoryEventHandler : org.apache.avro.AvroTypeException: Attempt to process a enum when a union was expected.
885,13,<*> org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: KILLING <*>
886,13,<*> org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy: Opening proxy : <*>
887,12,<*> org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl: cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>
888,12,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from <*> cleanup failed for container <*> : java.lang.IllegalArgumentException: java.net.UnknownHostException: <*>
889,3,"<*> org.apache.hadoop.ipc.Client: Retrying connect to server: msra-sa-41:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
890,3,<*> org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Exception while unregistering
891,3,<*> org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Skipping cleaning up the staging dir. assuming AM will be retried.
892,3,<*> org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Graceful stop failed
893,15,org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Recovery is enabled. Will try to recover from previous life on best effort basis.
894,19,org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Previous history file is at <*>
895,96,org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Read from history task <*>
896,11,org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Read completed tasks from history <*>
897,96,"[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Recovering task <*> from prior app attempt, status was SUCCEEDED"
898,529,"[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent <*> <*> <*> <*> <*> <*> <*> <*> <*> netScheduledReduceResource:<memory:0, vCores:0>"
899,804,[IPC Server handler <*> on 30607] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
900,182,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskImpl: Issuing kill to other attempt <*>
901,597,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: PendingReds:0 <*> <*> <*> <*> <*> CompletedReds:0 <*> ContRel:0 <*> <*>
902,212,[CommitterEvent Processor <*> org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete <*>
903,217,[Socket Reader #1 for port <*> org.apache.hadoop.ipc.Server: Socket Reader #1 for port <*> readAndProcess from client <*> threw exception [java.io.IOException: An existing connection was forcibly closed by the remote host]
904,3,[IPC Server handler <*> on 30607] <*> <*> <*> <*> <*> <*>
905,2,[Thread-116] <*> <*> notified that <*> <*> true
906,45,<*> org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:0 ScheduledMaps:0 ScheduledReds:0 AssignedMaps:0 <*> <*> <*> <*> <*> <*> <*>
907,562,[IPC Server handler <*> on 18836] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
908,3,[IPC Server handler <*> on 18836] <*> <*> <*> <*> <*> <*>
909,6,[Thread-112] <*> <*> notified that <*> <*> true
910,100,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Ramping down all scheduled reduces:0
911,100,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Going to preempt 1 due to lack of space for maps
912,497,[IPC Server handler <*> on 57861] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
913,3,[IPC Server handler <*> on 57861] <*> <*> <*> <*> <*> <*>
914,4,[Thread-111] <*> <*> notified that <*> <*> true
915,2,[Thread-71] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
916,20,<*> org.apache.hadoop.hdfs.DFSClient: Abandoning <*>
917,5,"org.apache.hadoop.hdfs.DFSClient: Failed to connect to <*> for block, add to deadNodes and continue. java.net.ConnectException: Connection timed out: no further information"
918,6,org.apache.hadoop.hdfs.DFSClient: Successfully connected to <*> for <*>
919,7,"[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Releasing unassigned and invalid container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:1024, vCores:1>, Priority: 20, Token: Token { kind: ContainerToken, service: <*> }, ]. RM may have assignment issues"
920,604,[IPC Server handler <*> on 53652] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
921,489,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: PendingReds:0 <*> ScheduledReds:0 <*> AssignedReds:1 <*> <*> <*> <*> <*> <*>
922,3,[IPC Server handler <*> on 53652] <*> <*> <*> <*> <*> <*>
923,4,[Thread-106] <*> <*> notified that <*> <*> true
924,25,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.JobImpl: TaskAttempt killed because it ran on unusable node <*> <*>
925,248,[IPC Server handler <*> on 32643] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
926,3,[IPC Server handler <*> on 32643] <*> <*> <*> <*> <*> <*>
927,2,[Thread-91] <*> <*> notified that <*> <*> true
928,84,[EventFetcher for fetching Map Completion Events] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Ignoring obsolete output of <*> map-task: <*>
929,7,org.apache.hadoop.mapred.Merger: Merging 4 intermediate segments out of a total of 13
930,20,[DataStreamer for file <*> org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
931,10,[DataStreamer for file <*> org.apache.hadoop.hdfs.DFSClient: Abandoning <*>
932,144,"[communication thread] org.apache.hadoop.ipc.Client: Retrying connect to server: <*> Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
933,1,[communication thread] org.apache.hadoop.mapred.Task: Communication exception: java.net.ConnectException: Call From MSRA-SA-39/172.22.149.145 to minint-fnanli5.fareast.corp.microsoft.com:49594 failed on connection exception: java.net.ConnectException: Connection timed out: no further information; For more details see: http://wiki.apache.org/hadoop/ConnectionRefused
934,6,"org.apache.hadoop.ipc.Client: Retrying connect to server: minint-fnanli5.fareast.corp.microsoft.com/10.86.169.121:49594. Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
935,989,[IPC Server handler <*> on 49594] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
936,55,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Killing <*> because it is running on unusable <*>
937,62,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from <*> <*> <*> <*> <*> <*> <*>
938,19,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from <*>
939,983,[IPC Server handler <*> on 57693] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
940,1209,[ContainerLauncher <*> org.apache.hadoop.ipc.Client: Retrying connect to server: <*> Already tried <*> time(s); maxRetries=45
941,416,"[ContainerLauncher <*> org.apache.hadoop.ipc.Client: Retrying connect to server: <*> Already tried <*> time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)"
942,909,[IPC Server handler <*> on 51066] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
943,3,[IPC Server handler <*> on 51066] <*> <*> <*> <*> <*> <*>
944,485,[IPC Server handler <*> on 53359] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
945,3,[IPC Server handler <*> on 53359] <*> <*> <*> <*> <*> <*>
946,2,[Thread-98] <*> <*> notified that <*> <*> true
947,534,[IPC Server handler <*> on 20059] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
948,3,[IPC Server handler <*> on 20059] <*> <*> <*> <*> <*> <*>
949,6,[Thread-104] <*> <*> notified that <*> <*> true
950,2530,[IPC Server handler <*> on 61655] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
951,155,[IPC Server handler <*> on 63463] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
952,3,[IPC Server handler <*> on 63463] <*> <*> <*> <*> <*> <*>
953,4,[Thread-79] <*> <*> notified that <*> <*> true
954,2,org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in <*>
955,2,<*> org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Shuffle failed : local error on this node: 04DN8IQ/10.86.164.138
956,4,org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Could not delete <*>
957,679,[IPC Server handler <*> on 51086] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
958,2,FATAL [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: <*> - exited : org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in <*>
959,2,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from <*> Error: org.apache.hadoop.mapreduce.task.reduce.Shuffle$ShuffleError: error in shuffle in <*>
960,1018,[IPC Server handler <*> on 52465] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
961,3,[IPC Server handler <*> on 52465] <*> <*> <*> <*> <*> <*>
962,2,[Thread-155] <*> <*> notified that <*> <*> true
963,893,[IPC Server handler <*> on 49792] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
964,1,FATAL [IPC Server handler 10 on 49792] org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: attempt_1445182159119_0002_m_000007_0 - exited : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_1445182159119_0002_m_000007_0/file.out
965,184,[IPC Server handler <*> on 44089] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
966,3,[IPC Server handler <*> on 44089] <*> <*> <*> <*> <*> <*>
967,2,[Thread-86] <*> <*> notified that <*> <*> true
968,1,org.apache.hadoop.mapred.MapTask: Ignoring exception during close for org.apache.hadoop.mapred.MapTask$NewOutputCollector@6a6585ee
969,1,org.apache.hadoop.mapred.YarnChild: Exception running child : org.apache.hadoop.util.DiskChecker$DiskErrorException: Could not find any valid local directory for output/attempt_1445182159119_0002_m_000007_0/file.out
970,6,[Thread-56] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
971,743,[IPC Server handler <*> on 40658] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
972,3,[IPC Server handler <*> on 40658] <*> <*> <*> <*> <*> <*>
973,15,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: After Scheduling: <*> <*> ScheduledReds:0 <*> AssignedReds:0 <*> <*> <*> <*> <*> <*>
974,2,[Thread-107] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
975,2,[Thread-110] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
976,779,[IPC Server handler <*> on 20324] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
977,3,[IPC Server handler <*> on 20324] <*> <*> <*> <*> <*> <*>
978,2,[Thread-120] <*> <*> notified that <*> <*> true
979,2,[Thread-123] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
980,2,[Thread-34] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
981,619,[IPC Server handler <*> on 47468] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
982,3,[IPC Server handler <*> on 47468] <*> <*> <*> <*> <*> <*>
983,4,[Thread-101] <*> <*> notified that <*> <*> true
984,4,"org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Unable to parse prior job history, aborting recovery"
985,4,org.apache.hadoop.mapreduce.v2.app.MRAppMaster: Could not parse the old history file. Will not have old AMinfos
986,796,[IPC Server handler <*> on 30358] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
987,3,[IPC Server handler <*> on 30358] <*> <*> <*> <*> <*> <*>
988,2,[Thread-110] <*> <*> notified that <*> <*> true
989,73,[IPC Server handler <*> on 62304] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
990,3880,[LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.hdfs.LeaseRenewer: Failed to renew lease for <*> for <*> seconds. Will retry shortly ...
991,2,[Thread-581] <*> <*> notified that <*> <*> true
992,1,[Thread-54] org.apache.hadoop.hdfs.DFSClient: DataStreamer Exception
993,1,org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Error closing writer for JobID: job_1445144423722_0023
994,2,<*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Found jobId <*> to have not been closed. Will close
995,2,<*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Error writing History Event: <*>
996,2,[Thread-581] org.apache.hadoop.service.AbstractService: Service <*> failed in state STOPPED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.nio.channels.ClosedChannelException
997,1,[Thread-581] org.apache.hadoop.service.CompositeService: When stopping the service JobHistoryEventHandler : org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.nio.channels.ClosedChannelException
998,1,[Thread-581] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Final Stats: PendingReds:1 ScheduledMaps:6 ScheduledReds:0 AssignedMaps:4 AssignedReds:0 CompletedMaps:0 CompletedReds:0 ContAlloc:4 ContRel:0 HostLocal:3 RackLocal:1
999,364,[IPC Server handler <*> on 55219] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1000,110,[IPC Server handler <*> on 24914] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1001,3,[IPC Server handler <*> on 24914] <*> <*> <*> <*> <*> <*>
1002,4,[Thread-78] <*> <*> notified that <*> <*> true
1003,1,[fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Connection retry failed with 4 attempts in 180 seconds
1004,1,[fetcher#3] org.apache.hadoop.mapreduce.task.reduce.Fetcher: Failed to connect to MININT-FNANLI5.fareast.corp.microsoft.com:13562 with 1 map outputs
1005,1,[fetcher#3] org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl: Reporting fetch failure for attempt_1445087491445_0004_m_000005_0 to jobtracker.
1006,446,[IPC Server handler <*> on 10559] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1007,1,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Preempting attempt_1445087491445_0004_r_000000_1000
1008,2,"[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: completedMapPercent <*> <*> <*> <*> <*> <*> <*> <*> <*> netScheduledReduceResource:<memory:1024, vCores:1>"
1009,3,[IPC Server handler <*> on 10559] <*> <*> <*> <*> <*> <*>
1010,2,[Thread-113] <*> <*> notified that <*> <*> true
1011,1295,[IPC Server handler <*> on 56794] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1012,3,[Thread-50] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Processing the event EventType: CONTAINER_DEALLOCATE
1013,2,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Error communicating with RM: Resource Manager doesn't recognize AttemptId: <*>
1014,2,[Thread-143] <*> <*> notified that <*> <*> false
1015,954,[IPC Server handler <*> on 53665] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1016,33,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: PendingReds:0 <*> <*> <*> <*> <*> CompletedReds:0 <*> ContRel:2 <*> <*>
1017,3,[IPC Server handler <*> on 53665] <*> <*> <*> <*> <*> <*>
1018,2,[Thread-115] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
1019,2,[Thread-96] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
1020,1,FATAL org.apache.hadoop.mapred.Task: Task attempt_1445182159119_0004_m_000004_0 failed : org.apache.hadoop.fs.FSError: java.io.IOException: There is not enough space on the disk
1021,945,[IPC Server handler <*> on 39673] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1022,6,FATAL [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: <*> - exited : java.io.IOException: There is not enough space on the disk
1023,8,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from <*> <*> java.io.IOException: There is not enough space on the disk
1024,2,FATAL [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: <*> - failed due to FSError: java.io.IOException: There is not enough space on the disk
1025,3,FATAL [IPC Server handler <*> on <*> org.apache.hadoop.mapred.TaskAttemptListenerImpl: Task: <*> - exited : java.io.IOException: Spill failed
1026,3,[AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from <*> Error: java.io.IOException: Spill failed
1027,8,"[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: Assigning container Container: [ContainerId: <*> NodeId: <*> NodeHttpAddress: <*> Resource: <memory:1024, vCores:1>, Priority: 5, Token: Token { kind: ContainerToken, service: <*> }, ] to fast fail map"
1028,3,[IPC Server handler <*> on 39673] <*> <*> <*> <*> <*> <*>
1029,2,[Thread-137] <*> <*> notified that <*> <*> true
1030,6,<*> org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: Copying <*> to hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging
1031,5,[Thread-137] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: <*> <*> <*> <*> hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging
1032,100,[IPC Server handler <*> on 24716] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1033,3,[IPC Server handler <*> on 24716] <*> <*> <*> <*> <*> <*>
1034,2,[Thread-24] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
1035,379,[IPC Server handler <*> on 55226] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1036,49,[IPC Server handler <*> on 58957] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1037,547,[IPC Server handler <*> on 56183] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1038,8,[Thread-54] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
1039,3,[IPC Server handler <*> on 56183] <*> <*> <*> <*> <*> <*>
1040,2,[Thread-109] <*> <*> notified that <*> <*> true
1041,164,[IPC Server handler <*> on 24300] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1042,3,[IPC Server handler <*> on 24300] <*> <*> <*> <*> <*> <*>
1043,2,[Thread-87] <*> <*> notified that <*> <*> true
1044,316,[IPC Server handler <*> on 58136] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1045,2,[Thread-85] <*> <*> notified that <*> <*> false
1046,793,[IPC Server handler <*> on 49479] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1047,3,[IPC Server handler <*> on 49479] <*> <*> <*> <*> <*> <*>
1048,628,[IPC Server handler <*> on 52881] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1049,3,[IPC Server handler <*> on 52881] <*> <*> <*> <*> <*> <*>
1050,450,[IPC Server handler <*> on 49470] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1051,418,[IPC Server handler <*> on 64410] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1052,3,[IPC Server handler <*> on 64410] <*> <*> <*> <*> <*> <*>
1053,2,[Thread-97] <*> <*> notified that <*> <*> true
1054,1503,[IPC Server handler <*> on 25280] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1055,3,[IPC Server handler <*> on 25280] <*> <*> <*> <*> <*> <*>
1056,2,[Thread-193] <*> <*> notified that <*> <*> true
1057,471,[IPC Server handler <*> on 47384] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1058,3,[IPC Server handler <*> on 47384] <*> <*> <*> <*> <*> <*>
1059,10,[communication thread] org.apache.hadoop.mapred.Task: Communication exception: java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to <*> failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
1060,5,[communication thread] org.apache.hadoop.mapred.Task: Process Thread Dump: Communication exception
1061,5,"[communication thread] org.apache.hadoop.mapred.Task: Last retry, killing <*>"
1062,1,"org.apache.hadoop.hdfs.DFSClient: Could not obtain BP-1347369012-10.190.173.170-1444972147527:blk_1073742989_2201 from any node: java.io.IOException: No live nodes contain block BP-1347369012-10.190.173.170-1444972147527:blk_1073742989_2201 after checking nodes = [172.22.149.145:50010, 10.190.173.170:50010], ignoredNodes = null No live nodes contain current block Block locations: 172.22.149.145:50010 10.190.173.170:50010 Dead nodes: 10.190.173.170:50010 172.22.149.145:50010 10.86.169.121:50010. Will get new block locations from namenode and retry..."
1063,1024,[IPC Server handler <*> on 43581] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1064,3,[IPC Server handler <*> on 43581] <*> <*> <*> <*> <*> <*>
1065,2,[Thread-141] <*> <*> notified that <*> <*> true
1066,533,[IPC Server handler <*> on 19667] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1067,3,[IPC Server handler <*> on 19667] <*> <*> <*> <*> <*> <*>
1068,2,[Thread-100] <*> <*> notified that <*> <*> true
1069,1042,[IPC Server handler <*> on 52529] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1070,3,[IPC Server handler <*> on 52529] <*> <*> <*> <*> <*> <*>
1071,2,[Thread-114] <*> <*> notified that <*> <*> true
1072,919,[IPC Server handler <*> on 29630] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1073,3,[IPC Server handler <*> on 29630] <*> <*> <*> <*> <*> <*>
1074,4,[Thread-115] <*> <*> notified that <*> <*> true
1075,4,[Thread-125] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
1076,1,"org.apache.hadoop.hdfs.DFSClient: Failed to connect to /10.86.169.121:50010 for block, add to deadNodes and continue. java.net.ConnectException: Connection refused: no further information"
1077,915,[IPC Server handler <*> on 32070] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1078,3,[IPC Server handler <*> on 32070] <*> <*> <*> <*> <*> <*>
1079,2,[Thread-147] <*> <*> notified that <*> <*> true
1080,750,[IPC Server handler <*> on 60153] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1081,3,[IPC Server handler <*> on 60153] <*> <*> <*> <*> <*> <*>
1082,2,[Thread-123] <*> <*> notified that <*> <*> true
1083,2,[Thread-128] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
1084,721,[IPC Server handler <*> on 17464] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1085,3,[IPC Server handler <*> on 17464] <*> <*> <*> <*> <*> <*>
1086,2,[Thread-108] <*> <*> notified that <*> <*> true
1087,5,[Thread-108] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: <*> <*> <*> <*> hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging
1088,448,[IPC Server handler <*> on 57581] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1089,3,[IPC Server handler <*> on 57581] <*> <*> <*> <*> <*> <*>
1090,4,[Thread-94] <*> <*> notified that <*> <*> true
1091,5,[Thread-94] org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler: <*> <*> <*> <*> hdfs://msra-sa-41:9000/tmp/hadoop-yarn/staging
1092,744,[IPC Server handler <*> on 63282] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1093,3,[IPC Server handler <*> on 63282] <*> <*> <*> <*> <*> <*>
1094,521,[IPC Server handler <*> on 4236] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1095,3,[IPC Server handler <*> on 4236] <*> <*> <*> <*> <*> <*>
1096,543,[IPC Server handler <*> on 19061] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1097,1,[IPC Server handler 27 on 19061] org.apache.hadoop.mapred.TaskAttemptListenerImpl: MapCompletionEvents reques
1098,49,[IPC Server handler <*> on 58950] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1099,1110,[IPC Server handler <*> on 64927] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1100,3,[IPC Server handler <*> on 64927] <*> <*> <*> <*> <*> <*>
1101,2,[Thread-117] <*> <*> notified that <*> <*> true
1102,447,[IPC Server handler <*> on 4824] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1103,3,[IPC Server handler <*> on 4824] <*> <*> <*> <*> <*> <*>
1104,1358,[IPC Server handler <*> on 22927] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1105,3,[IPC Server handler <*> on 22927] <*> <*> <*> <*> <*> <*>
1106,26,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: <*> ScheduledMaps:0 ScheduledReds:0 <*> AssignedReds:0 <*> <*> <*> ContRel:0 <*> <*>
1107,2,[Thread-158] <*> <*> notified that <*> <*> true
1108,2,[Thread-163] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
1109,581,[IPC Server handler <*> on 39935] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1110,556,[IPC Server handler <*> on 52155] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1111,2,[Thread-626] <*> <*> notified that <*> <*> true
1112,2,[Thread-626] org.apache.hadoop.service.AbstractService: Service <*> failed in state STOPPED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: java.net.NoRouteToHostException: No Route to Host from MININT-FNANLI5/127.0.0.1 to msra-sa-41:9000 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host: no further information; For more details see: http://wiki.apache.org/hadoop/NoRouteToHost
1113,143,[IPC Server handler <*> on 4415] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1114,3,[IPC Server handler <*> on 4415] <*> <*> <*> <*> <*> <*>
1115,2,[Thread-81] <*> <*> notified that <*> <*> true
1116,764,[IPC Server handler <*> on 11421] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1117,156,[IPC Server handler <*> on 53993] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1118,746,[IPC Server handler <*> on 52839] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1119,172,[IPC Server handler <*> on 19911] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1120,3,[IPC Server handler <*> on 19911] <*> <*> <*> <*> <*> <*>
1121,1049,[IPC Server handler <*> on 53419] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1122,1,[LeaseRenewer:msrabi@msra-sa-41:9000] org.apache.hadoop.ipc.Client: Retrying connect to server: msra-sa-41/10.190.173.170:9000. Already tried 0 time(s); maxRetries=45
1123,1087,[IPC Server handler <*> on 58622] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1124,6,[RMCommunicator Allocator] org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator: <*> Scheduling: PendingReds:0 <*> <*> <*> <*> <*> CompletedReds:0 <*> ContRel:1 HostLocal:7 <*>
1125,1,"[IPC Server handler 29 on 58622] org.apache.hadoop.ipc.Server: IPC Server handler 29 on 58622, call statusUpdate(attempt_1445094324383_0003_m_000000_0, org.apache.hadoop.mapred.MapTaskStatus@cdcdbf7), rpc version=2, client version=19, methodsFingerPrint=937413979 from 10.86.169.121:52490 Call#68 Retry#0: output error"
1126,1,[IPC Server handler 29 on 58622] org.apache.hadoop.ipc.Server: IPC Server handler 29 on 58622 caught an exception
1127,3,[IPC Server handler <*> on 58622] <*> <*> <*> <*> <*> <*>
1128,2,[Thread-138] <*> <*> notified that <*> <*> true
1129,1209,[IPC Server handler <*> on 49451] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1130,3,[IPC Server handler <*> on 49451] <*> <*> <*> <*> <*> <*>
1131,2,[Thread-122] <*> <*> notified that <*> <*> true
1132,2,[Thread-93] org.apache.hadoop.hdfs.DFSClient: <*> <*> <*>
1133,836,[IPC Server handler <*> on 19304] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1134,3,[IPC Server handler <*> on 19304] <*> <*> <*> <*> <*> <*>
1135,2,[Thread-152] <*> <*> notified that <*> <*> true
1136,1349,[IPC Server handler <*> on 55796] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1137,1,[IPC Server handler 28 on 55796] org.apache.hadoop.map
1138,1231,[IPC Server handler <*> on 30954] org.apache.hadoop.mapred.TaskAttemptListenerImpl: <*> <*> <*> <*> <*> <*> <*>
1139,3,[IPC Server handler <*> on 30954] <*> <*> <*> <*> <*> <*>
1140,2,[Thread-159] <*> <*> notified that <*> <*> true
